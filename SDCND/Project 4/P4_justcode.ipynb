{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Project 4: Advanced Lane Finding** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **REFERENCES**\n",
    "https://github.com/udacity/CarND-Camera-Calibration/blob/master/camera_calibration.ipynb\n",
    "\n",
    "https://carnd-forums.udacity.com/questions/38543970/p4-birds-eye-transformation-after-masking-throws-error-assertion-failed-ifunc-0-in-remap-file\n",
    "\n",
    "https://chatbotslife.com/robust-lane-finding-using-advanced-computer-vision-techniques-46875bb3c8aa#.uoh0q8oc2\n",
    "\n",
    "https://carnd-forums.udacity.com/questions/38535979/p4-are-suggested-reference-points-good-enough\n",
    "\n",
    "https://carnd-forums.udacity.com/questions/29494501/birds-eye-view-transform"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **LOAD PACKAGES**\n",
    "Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "from matplotlib.path import Path\n",
    "import matplotlib.patches as patches\n",
    "from scipy import ndimage as ndi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LOAD IMAGES**\n",
    "Load the calibration and test images and check to make sure they loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Calibration Images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "# Load Test Images\n",
    "testimages = glob.glob('test_images/*.jpg')\n",
    "\n",
    "# Test to make sure that the camera calibration images are loading properly\n",
    "testimg   = cv2.imread(images[2],3)\n",
    "testimg   = cv2.cvtColor(testimg,cv2.COLOR_BGR2RGB)\n",
    "plt.figure(0)\n",
    "plt.imshow(testimg)\n",
    "# Test to make sure that the test images are loading properly\n",
    "testimg   = cv2.imread(testimages[2],3)\n",
    "testimg   = cv2.cvtColor(testimg,cv2.COLOR_BGR2RGB)\n",
    "plt.figure(1)\n",
    "plt.imshow(testimg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** CAMERA CALIBRATION **\n",
    "Do corner detection on each of the camera calibration images and compute the camera calibration matricies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Detect Corners\n",
    "def CornerDetectTest(img):\n",
    "    nx = 9 #Number of inside corners in x\n",
    "    ny = 6 #Number of inside corners in y\n",
    "    # Convert to Grayscale\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (nx,ny), None)\n",
    "    # If found, draw coreners\n",
    "    if ret == True:\n",
    "        #Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img,(nx,ny),corners, ret)   \n",
    "        plt.imshow(img)\n",
    "# Test to make sure corners are detected\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(idx)\n",
    "    CornerDetectTest(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Compute Camera Calibration Parameters\n",
    "# prepare object points\n",
    "objp = np.zeros((6*9,3), np.float32)\n",
    "objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1,2)\n",
    "\n",
    "# Arrays to store object points and image points from all the images.\n",
    "objpoints = [] # 3d points in real world space\n",
    "imgpoints = [] # 2d points in image plane.\n",
    "\n",
    "# Make a list of calibration images\n",
    "images = glob.glob('camera_cal/calibration*.jpg')\n",
    "\n",
    "# Step through the list and search for chessboard corners\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "\n",
    "    # Find the chessboard corners\n",
    "    ret, corners = cv2.findChessboardCorners(gray, (9,6), None)\n",
    "\n",
    "    # If found, add object points, image points\n",
    "    if ret == True:\n",
    "        objpoints.append(objp)\n",
    "        imgpoints.append(corners)\n",
    "\n",
    "        # Draw and display the corners\n",
    "        cv2.drawChessboardCorners(img, (9,6), corners, ret)\n",
    "        # Save calibrated images to disk\n",
    "        write_name = 'camera_cal/corners_found'+str(idx)+'.jpg'\n",
    "        cv2.imwrite(write_name, img)\n",
    "\n",
    "# Do camera calibration given object points and image points\n",
    "ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, img_size,None,None)\n",
    "\n",
    "# Save the camera calibration\n",
    "dist_pickle = {}\n",
    "dist_pickle[\"mtx\"]  = mtx\n",
    "dist_pickle[\"dist\"] = dist\n",
    "pickle.dump( dist_pickle, open( \"output_images/camera_cal.p\", \"wb\" ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Function to un-distort images\n",
    "def undistort_imgs(img,outputimg='') :\n",
    "    # Load Camera Calibration Coefficients\n",
    "    PickleCal = pickle.load( open( \"output_images/camera_cal.p\", \"rb\" ) )\n",
    "    mtx  = PickleCal[\"mtx\"]\n",
    "    dist = PickleCal[\"dist\"]\n",
    "    # Test undistortion on an image\n",
    "    img_size = (img.shape[1], img.shape[0])\n",
    "    dst = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    if not(outputimg == ''):\n",
    "        cv2.imwrite(outputimg,dst)\n",
    "    return dst\n",
    "# Test to make sure camera calibration worked on all camera calibration images\n",
    "for idx, fname in enumerate(images):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(idx)\n",
    "    write_cal_img = 'output_images/calibration'+str(idx)+'_calibrated.jpg'\n",
    "    dst = undistort_imgs(img,write_cal_img)    \n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test to make sure camera calibration worked on all test images\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(idx)\n",
    "    write_tst_img = 'output_images/test_images_'+str(idx)+'_calibrated.jpg'\n",
    "    dst = undistort_imgs(img,write_tst_img)    \n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original', fontsize=30)\n",
    "    ax2.imshow(dst)\n",
    "    ax2.set_title('Undistorted', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** PERSPECTIVE TRANSFORM **\n",
    "Compute the birds eye perspective transform on the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def BirdsEyeTransform(img):   \n",
    "    h           = img.shape[0]\n",
    "    w           = img.shape[1]\n",
    "    img_size    = (w, h)\n",
    "    src         = np.float32([[583, 460], [203, 720], [1127, 720], [705, 460]])\n",
    "    dst         = np.float32([[320, 0], [320, 720], [960,720], [960, 0]])\n",
    "    M           = cv2.getPerspectiveTransform(src, dst)\n",
    "    img_size    = (img.shape[1], img.shape[0])\n",
    "    binary_warped = cv2.warpPerspective(img, M, img_size, flags=cv2.INTER_LINEAR)\n",
    "    M_inv       = np.linalg.inv(M)\n",
    "    return binary_warped, M_inv\n",
    "# Test that BirdsEyeTransform works\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(idx)\n",
    "    write_tst_img = ''\n",
    "    img = undistort_imgs(img,write_tst_img)\n",
    "    bdeyeimg,M_inv = BirdsEyeTransform(img)\n",
    "    # Take points for plotting source and destination warp\n",
    "    src       = np.float32([[583, 460], [203, 720], [1127, 720], [705, 460]])\n",
    "    dst       = np.float32([[320, 0], [320, 720], [960,720], [960, 0]])\n",
    "    h, w, c     = img.shape\n",
    "    img_size    = (w, h)\n",
    "    # Visualize BirdsEyeTransform\n",
    "    plt.figure(idx)\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    \n",
    "    # Draw the test image and the polygon\n",
    "    verts = [src[0], src[1], src[2], src[3], src[0]]\n",
    "    codes = [Path.MOVETO,Path.LINETO,Path.LINETO,Path.LINETO,Path.CLOSEPOLY]\n",
    "    path  = Path(verts, codes)\n",
    "    patch = patches.PathPatch(path, color='red', fill=False, lw=2)\n",
    "    ax1.add_patch(patch)\n",
    "    ax1.set_title('Original', fontsize=30)\n",
    "    ax2.imshow(bdeyeimg)\n",
    "    verts = [dst[0], dst[1], dst[2], dst[3], dst[0]]\n",
    "    codes = [Path.MOVETO,Path.LINETO,Path.LINETO,Path.LINETO,Path.CLOSEPOLY]\n",
    "    path  = Path(verts, codes)\n",
    "    patch = patches.PathPatch(path, color='red', fill=False, lw=2)\n",
    "    ax2.add_patch(patch)\n",
    "    ax2.set_title('Birds Eye', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** COLOR THRESHOLDING TESTS **\n",
    "Perform color thresholding to pick out the white and yellow lanes in the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Combined Color Thresholding: Identify White and Yellow Pixels in the image\n",
    "def ColorThresh(img):\n",
    "    hsv        = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    hls        = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    maskyellow = cv2.inRange(hsv, np.array([ 20, 0, 0]), np.array([ 30, 255, 255]))\n",
    "    maskwhite  = cv2.inRange(hls, np.array([ 0, 200, 0]), np.array([ 255, 255, 255]))\n",
    "    mask       = cv2.bitwise_or(maskyellow,maskwhite)\n",
    "    out        = cv2.bitwise_and(img,img, mask=mask)\n",
    "    return out     \n",
    "\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(idx)\n",
    "    write_tst_img = ''\n",
    "    img, undistort_imgs(img,write_tst_img)\n",
    "    \n",
    "    #thresholded = ColorThresh(bdeyeimg)\n",
    "    r = img[:,:,0]\n",
    "    g = img[:,:,1]\n",
    "    b = img[:,:,2]\n",
    "    color_binary = np.zeros_like(r)\n",
    "    yellow = [[215, 255], [140, 255], [  0, 160]]\n",
    "    white  = [[225, 255], [225, 255], [225, 255]]\n",
    "    color_binary[((( r > 215) & (r <  255)) &(( g > 140) & (g <  255)) &(( b >   0) & (b <  160)))\n",
    "                 |(((r > 225) & (r <  255)) &(( g > 225) & (g <  255)) &(( b > 225) & (b <  255)))] = 1\n",
    "    bdeyeimg,M_inv = BirdsEyeTransform(color_binary)\n",
    "    # Visualize Thresholded Images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original', fontsize=30)\n",
    "    ax2.imshow(bdeyeimg, cmap='gray')\n",
    "    ax2.set_title('Color Thresholded', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** COLOR SPACES TESTING**\n",
    "Visualize the different channels of HSV, HSL and RGB to determine which are best to use for gradient thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HSV Channels Plotting\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "    plt.figure(idx)\n",
    "    img_hsv = undistort_imgs(img_hsv)\n",
    "    bdeyeimg,M_inv = BirdsEyeTransform(img_hsv)\n",
    "    h_chan = bdeyeimg[:,:,0]\n",
    "    s_chan = bdeyeimg[:,:,1]\n",
    "    v_chan = bdeyeimg[:,:,2]\n",
    "    # Visualize Thresholded Images\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original', fontsize=30)\n",
    "    ax2.imshow(h_chan, cmap='gray')\n",
    "    ax2.set_title('HSV H Channel', fontsize=30)\n",
    "    ax3.imshow(s_chan, cmap='gray')\n",
    "    ax3.set_title('HSV S Channel', fontsize=30)\n",
    "    ax4.imshow(v_chan, cmap='gray')\n",
    "    ax4.set_title('HSV V Channel', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# RGB Channels Plotting\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(idx)\n",
    "    img = undistort_imgs(img)\n",
    "    bdeyeimg,M_inv = BirdsEyeTransform(img)\n",
    "    r_chan = bdeyeimg[:,:,0]\n",
    "    g_chan = bdeyeimg[:,:,1]\n",
    "    b_chan = bdeyeimg[:,:,2]\n",
    "    # Visualize Thresholded Images\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(r_chan, cmap='gray')\n",
    "    ax2.set_title('RGB R Channel', fontsize=30)\n",
    "    ax3.imshow(g_chan, cmap='gray')\n",
    "    ax3.set_title('RGB G Channel', fontsize=30)\n",
    "    ax4.imshow(b_chan, cmap='gray')\n",
    "    ax4.set_title('RGB B Channel', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# HLS Channels Plotting\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    plt.figure(idx)\n",
    "    img_hls = undistort_imgs(img_hls)\n",
    "    bdeyeimg,M_inv = BirdsEyeTransform(img_hls)\n",
    "    h_chan = bdeyeimg[:,:,0]\n",
    "    l_chan = bdeyeimg[:,:,1]\n",
    "    s_chan = bdeyeimg[:,:,2]\n",
    "    # Visualize Thresholded Images\n",
    "    f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(h_chan, cmap='gray')\n",
    "    ax2.set_title('HLS H Channel', fontsize=30)\n",
    "    ax3.imshow(l_chan, cmap='gray')\n",
    "    ax3.set_title('HLS L Channel', fontsize=30)\n",
    "    ax4.imshow(s_chan, cmap='gray')\n",
    "    ax4.set_title('HLS S Channel', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** GRADIENT COMBINED THRESHOLDING ***\n",
    "Test different kinds of Sobel gradient thresholding, pick one that works best with color thresholding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def sobel_absx(img,sobel_kernel,threshx_min=20,threshx_max=80):\n",
    "    # SOBEL: Directional X \n",
    "    img_dx     = cv2.Sobel(img,cv2.CV_64F, 1, 0)\n",
    "    img_absx   = np.absolute(img_dx)\n",
    "    img_sobelx = np.uint8(255*img_absx/np.max(img_absx))\n",
    "    sobel_dirx = np.zeros_like(img_sobelx)\n",
    "    sobel_dirx[(img_sobelx >= threshx_min) & (img_sobelx <= threshx_max)] = 1\n",
    "    return sobel_dirx\n",
    "def sobel_absy(img,sobel_kernel,threshy_min=80,threshy_max=225):\n",
    "    # SOBEL: Directional Y \n",
    "    img_dy     = cv2.Sobel(img,cv2.CV_64F, 0, 1)\n",
    "    img_absy   = np.absolute(img_dy)\n",
    "    img_sobely = np.uint8(255*img_absy/np.max(img_absy))\n",
    "    sobel_diry = np.zeros_like(img_sobely)\n",
    "    sobel_diry[(img_sobely >= threshy_min) & (img_sobely <= threshy_max)] = 1\n",
    "    return sobel_diry\n",
    "def sobel_mag(img,sobel_kernel,threshmag_min =  20,threshmag_max = 120):  \n",
    "    # SOBEL: Magnitude\n",
    "    sobelmx = cv2.Sobel(img,cv2.CV_64F, 1, 0)\n",
    "    sobelmy = cv2.Sobel(img,cv2.CV_64F, 0, 1)\n",
    "    mag_sobel    = np.sqrt(sobelmx**2 + sobelmx**2)\n",
    "    scaled_sobel = np.uint8(mag_sobel*255/np.max(mag_sobel))\n",
    "    sobel_mag    = np.zeros_like(scaled_sobel)\n",
    "    sobel_mag[(scaled_sobel>=threshmag_min) & (scaled_sobel<=threshmag_max) ]=1\n",
    "    return sobel_mag\n",
    "def sobel_dir(img,sobel_kernel,threshd_min= 0.5,threshd_max= 1.2):\n",
    "    # SOBEL: Calculate gradient direction\n",
    "    sobeldx    = cv2.Sobel(img,cv2.CV_64F,1,0, ksize=sobel_kernel)\n",
    "    sobeldy    = cv2.Sobel(img,cv2.CV_64F,0,1, ksize=sobel_kernel)\n",
    "    abs_sobelx = np.absolute(sobeldx)\n",
    "    abs_sobely = np.absolute(sobeldy)\n",
    "    dir_grad   = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    sobel_dir    = np.zeros_like(dir_grad)\n",
    "    sobel_dir[(dir_grad>=threshd_min) & (dir_grad<=threshd_max)] = 1\n",
    "    return sobel_dir\n",
    "def combined_color(img):\n",
    "    r = img[:,:,0]\n",
    "    g = img[:,:,1]\n",
    "    b = img[:,:,2]\n",
    "    color_binary = np.zeros_like(b)\n",
    "    yellow = [[215, 255], [140, 255], [  0, 160]]\n",
    "    white  = [[225, 255], [225, 255], [225, 255]]\n",
    "    color_binary[((( r > 215) & (r <  255)) &(( g > 140) & (g <  255)) &(( b >   0) & (b <  160)))\n",
    "                 |(((r > 225) & (r <  255)) &(( g > 225) & (g <  255)) &(( b > 225) & (b <  255)))] = 1\n",
    "    return color_binary\n",
    "    \n",
    "for idx, fname in enumerate(testimages):\n",
    "    img       = cv2.imread(fname)\n",
    "    img       = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_hls   = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    img_gs    = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    hls       = undistort_imgs(img_hls)\n",
    "    gs        = undistort_imgs(img_gs)\n",
    "    rgb       = undistort_imgs(img)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    color_binary = combined_color(rgb);\n",
    "    \n",
    "    #sobel_chan = gs\n",
    "    sobel_chan = s_channel\n",
    "    \n",
    "    bin_out_absx = sobel_absx(sobel_chan,21,20,100)\n",
    "    bin_out_absy = sobel_absy(sobel_chan,3)\n",
    "    bin_out_mag  = sobel_mag(sobel_chan,3)\n",
    "    bin_out_dir  = sobel_dir(sobel_chan,3,120,225)\n",
    "    combo_test = np.zeros_like(bin_out_absx)\n",
    "    combo_test[((bin_out_absx == 1) & (color_binary == 1))]= 1\n",
    "    bdeyeimg_absx,M_inv = BirdsEyeTransform(bin_out_absx)\n",
    "    bdeyeimg_absy,M_inv = BirdsEyeTransform(bin_out_absy)\n",
    "    bdeyeimg_mag,M_inv  = BirdsEyeTransform(bin_out_mag)\n",
    "    bdeyeimg_dir,M_inv  = BirdsEyeTransform(bin_out_dir)\n",
    "    bdeyeimg_clr,M_inv  = BirdsEyeTransform(combo_test)\n",
    "    \n",
    "    # Visualize Thresholded Images\n",
    "    plt.figure(idx)\n",
    "    f, (ax1, ax2, ax3, ax4, ax5) = plt.subplots(1, 5, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original', fontsize=30)\n",
    "    ax2.imshow(bdeyeimg_absx, cmap='gray')\n",
    "    ax2.set_title('Sobel ABSx', fontsize=30)\n",
    "    ax3.imshow(bdeyeimg_absy, cmap='gray')\n",
    "    ax3.set_title('Sobel ABSy', fontsize=30)\n",
    "    ax4.imshow(bdeyeimg_mag, cmap='gray')\n",
    "    ax4.set_title('Sobel Mag', fontsize=30)\n",
    "    ax5.imshow(bdeyeimg_clr, cmap='gray')\n",
    "    ax5.set_title('Clr + ABSx', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** COMBINED COLOR & GRADIENT THRESHOLDING **\n",
    "Test combined color and gradient thresholding to form binary images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pipeline_binary_img_test(img_rgb):\n",
    "    img_hls   = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2HLS)\n",
    "    img_gs    = cv2.cvtColor(img_rgb, cv2.COLOR_RGB2GRAY)\n",
    "    hls       = undistort_imgs(img_hls)\n",
    "    gs        = undistort_imgs(img_gs)\n",
    "    rgb       = undistort_imgs(img_rgb)\n",
    "    h_channel = hls[:,:,0]\n",
    "    l_channel = hls[:,:,1]\n",
    "    s_channel = hls[:,:,2]\n",
    "    \n",
    "    color_binary = combined_color(rgb);\n",
    "    \n",
    "    sobel_chan = gs\n",
    "    #sobel_chan = s_channel\n",
    "    \n",
    "    bin_out_absx = sobel_absx(sobel_chan,3,20,100)\n",
    "    combo_test = np.zeros_like(bin_out_absx)\n",
    "    combo_test[((bin_out_absx == 1) | (color_binary == 1))]= 1\n",
    "    \n",
    "    return combo_test\n",
    "\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(idx)\n",
    "    thresholded    = pipeline_binary_img_test(img)\n",
    "    bdeyeimg,M_inv = BirdsEyeTransform(thresholded)\n",
    "    # Visualize Thresholded Images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(img)\n",
    "    ax1.set_title('Original', fontsize=30)\n",
    "    ax2.imshow(bdeyeimg, cmap='gray')\n",
    "    ax2.set_title('Thresholded', fontsize=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# In all of the frames the lanes appear within the x range of 200 to 1200, we want to remove extra points\n",
    "# outside this range that are giving false measurements, this includes things like the concrete road dividers\n",
    "# on the left side of the image.\n",
    "\n",
    "def region_of_interest(img, vertices):\n",
    "    #defining a blank mask to start with\n",
    "    mask = np.zeros_like(img)   \n",
    "    \n",
    "    #defining a 3 channel or 1 channel color to fill the mask with depending on the input image\n",
    "    if len(img.shape) > 2:\n",
    "        channel_count = img.shape[2]  # i.e. 3 or 4 depending on your image\n",
    "        ignore_mask_color = (255,) * channel_count\n",
    "    else:\n",
    "        ignore_mask_color = 255\n",
    "        \n",
    "    #filling pixels inside the polygon defined by \"vertices\" with the fill color    \n",
    "    cv2.fillPoly(mask, vertices, ignore_mask_color)\n",
    "    \n",
    "    #returning the image only where mask pixels are nonzero\n",
    "    masked_image = cv2.bitwise_and(img, mask)\n",
    "    return masked_image\n",
    "\n",
    "def filter_outliers(thresholded, filtersize):\n",
    "\n",
    "    filtered = np.zeros_like(thresholded)\n",
    "    \n",
    "    label_objects, nb_labels = ndi.label(thresholded)\n",
    "    sizes = np.bincount(label_objects.ravel())\n",
    "\n",
    "    mask_sizes = sizes > filtersize\n",
    "    mask_sizes[0] = 0\n",
    "    thresholded = mask_sizes[label_objects]\n",
    "    \n",
    "    whites = thresholded > 0\n",
    "    \n",
    "    filtered[whites] = 1\n",
    "    \n",
    "    return filtered\n",
    "\n",
    "def mask_bdseye(bdeyeimg):\n",
    "    imshape         = bdeyeimg.shape\n",
    "    x_dim           = imshape[1]\n",
    "    y_dim           = imshape[0]\n",
    "    vertices        = np.array([ [(200,0), (200,720), (1200,720), (1200,0)]], dtype=np.int32)\n",
    "    masked_img      = region_of_interest(bdeyeimg, vertices)\n",
    "    return masked_img\n",
    "\n",
    "# Test to make sure masking worked\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img = cv2.imread(fname)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    plt.figure(idx)\n",
    "    thresholded    = pipeline_binary_img_test(img)\n",
    "    bdeyeimg,M_inv = BirdsEyeTransform(thresholded)  \n",
    "    bdeyeimg       = filter_outliers(bdeyeimg,30)\n",
    "    masked_img     = mask_bdseye(bdeyeimg)\n",
    "    # Visualize undistortion\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    plotvertices    = np.float32([[200,0], [200,720], [1200,720], [1200,0]])\n",
    "    verts = [plotvertices[0], plotvertices[1], plotvertices[2], plotvertices[3], plotvertices[0]]\n",
    "    codes = [Path.MOVETO,Path.LINETO,Path.LINETO,Path.LINETO,Path.CLOSEPOLY]\n",
    "    path  = Path(verts, codes)\n",
    "    patch = patches.PathPatch(path, color='red', fill=False, lw=2)\n",
    "    ax1.imshow(bdeyeimg)\n",
    "    ax1.add_patch(patch)\n",
    "    ax1.set_title('Original', fontsize=30)\n",
    "    ax2.imshow(masked_img)\n",
    "    ax2.set_title('Masked', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** IMAGE PREPROCESSING TEST **\n",
    "Test that the combined image processing is working properly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def preprocessimage(img):\n",
    "    # Apply Distortion Correction\n",
    "    undistortedimg = undistort_imgs(img)\n",
    "    # Apply Binary Thresholding\n",
    "    thresholded     = pipeline_binary_img_test(img)\n",
    "    # Apply Perspective Transform\n",
    "    bdeyeimg,M_inv = BirdsEyeTransform(thresholded)\n",
    "    bdeyeimg       = filter_outliers(bdeyeimg,30)\n",
    "    bdeyeimg       = mask_bdseye(bdeyeimg)\n",
    "    yield bdeyeimg\n",
    "    yield undistortedimg\n",
    "    yield M_inv\n",
    " \n",
    "for idx, fname in enumerate(testimages):\n",
    "    img            = cv2.imread(fname)\n",
    "    img            = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_proc,undist,M_inv = preprocessimage(img)\n",
    "    # Visualize Preprocessed images\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "    ax1.imshow(undist)\n",
    "    ax1.set_title('Original Image', fontsize=30)\n",
    "    ax2.imshow(img_proc, cmap='gray')\n",
    "    ax2.set_title('Preprocessed Image', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** LANE DETECTION **\n",
    "Perform lane detection algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Draw Histograms to Visualize Detection of Lanes\n",
    "figure = plt.figure(1,figsize=(18, 20))\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img      = cv2.imread(fname)\n",
    "    img      = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_proc,undist,M_inv = preprocessimage(img)\n",
    "    # Visualize Histograms Across Preprocessed Images\n",
    "    figure.add_subplot(4,2,idx+1)\n",
    "    plt.imshow(img_proc, cmap='gray')\n",
    "    histogram = np.sum(img_proc[img_proc.shape[0]/2:,:], axis=0)\n",
    "    plt.plot(histogram,'r')\n",
    "    plt.ylabel('Y Pixels / Counts')\n",
    "    plt.xlabel('X Pixels / Pixel Position')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def lane_find(img):\n",
    "    # Assuming you have created a warped binary image\n",
    "    # Take a histogram of the bottom half of the image\n",
    "    histogram = np.sum(img[img.shape[0]/2:,:], axis=0)\n",
    "    # Create an output image to draw on and  visualize the result\n",
    "    out_img = np.dstack((img, img, img))*255\n",
    "    # Find the peak of the left and right halves of the histogram\n",
    "    # These will be the starting point for the left and right lines\n",
    "    midpoint    = np.int(histogram.shape[0]/2)\n",
    "    leftx_base  = np.argmax(histogram[:midpoint])\n",
    "    rightx_base = np.argmax(histogram[midpoint:]) + midpoint\n",
    "    # Choose the number of sliding windows\n",
    "    nwindows    = 9\n",
    "    # Set height of windows\n",
    "    window_height = np.int(img.shape[0]/nwindows)\n",
    "    # Identify the x and y positions of all nonzero pixels in the image\n",
    "    nonzero  = img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    # Current positions to be updated for each window\n",
    "    leftx_current  = leftx_base\n",
    "    rightx_current = rightx_base\n",
    "    # Set the width of the windows +/- margin\n",
    "    margin = 110\n",
    "    # Set minimum number of pixels found to recenter window\n",
    "    minpix = 100\n",
    "    # Create empty lists to receive left and right lane pixel indices\n",
    "    left_lane_inds  = []\n",
    "    right_lane_inds = []\n",
    "\n",
    "    # Step through the windows one by one\n",
    "    for window in range(nwindows):\n",
    "        # Identify window boundaries in x and y (and right and left)\n",
    "        win_y_low       = img.shape[0]  - (window+1)*window_height\n",
    "        win_y_high      = img.shape[0]  - window*window_height\n",
    "        win_xleft_low   = leftx_current  - margin\n",
    "        win_xleft_high  = leftx_current  + margin\n",
    "        win_xright_low  = rightx_current - margin\n",
    "        win_xright_high = rightx_current + margin\n",
    "        # Draw the windows on the visualization image\n",
    "        cv2.rectangle(out_img,(win_xleft_low,win_y_low),(win_xleft_high,win_y_high),(0,255,0), 2) \n",
    "        cv2.rectangle(out_img,(win_xright_low,win_y_low),(win_xright_high,win_y_high),(0,255,0), 2) \n",
    "        # Identify the nonzero pixels in x and y within the window\n",
    "        good_left_inds  = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xleft_low) & (nonzerox < win_xleft_high)).nonzero()[0]\n",
    "        good_right_inds = ((nonzeroy >= win_y_low) & (nonzeroy < win_y_high) & (nonzerox >= win_xright_low) & (nonzerox < win_xright_high)).nonzero()[0]\n",
    "        # Append these indices to the lists\n",
    "        left_lane_inds.append(good_left_inds)\n",
    "        right_lane_inds.append(good_right_inds)\n",
    "        # If you found > minpix pixels, recenter next window on their mean position\n",
    "        if len(good_left_inds) > minpix:\n",
    "            leftx_current = np.int(np.mean(nonzerox[good_left_inds]))\n",
    "        if len(good_right_inds) > minpix:        \n",
    "            rightx_current = np.int(np.mean(nonzerox[good_right_inds]))\n",
    "\n",
    "    # Concatenate the arrays of indices\n",
    "    left_lane_inds  = np.concatenate(left_lane_inds)\n",
    "    right_lane_inds = np.concatenate(right_lane_inds)\n",
    "\n",
    "    # Extract left and right line pixel positions\n",
    "    leftx  = nonzerox[left_lane_inds]\n",
    "    lefty  = nonzeroy[left_lane_inds] \n",
    "    rightx = nonzerox[right_lane_inds]\n",
    "    righty = nonzeroy[right_lane_inds] \n",
    "\n",
    "    # Fit a second order polynomial to each\n",
    "    left_fit  = np.polyfit(lefty, leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    ploty      = np.linspace(0, img.shape[0]-1, img.shape[0] )\n",
    "    left_fitx  = left_fit[0]*ploty**2 +  left_fit[1]*ploty + left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    yield out_img\n",
    "    yield left_fitx\n",
    "    yield right_fitx\n",
    "    yield left_fit\n",
    "    yield right_fit\n",
    "    yield ploty\n",
    "    yield left_lane_inds\n",
    "    yield right_lane_inds\n",
    "    yield nonzerox\n",
    "    yield nonzeroy\n",
    "\n",
    "figure = plt.figure(1,figsize=(18, 20))\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img            = cv2.imread(fname)\n",
    "    img            = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_proc,undist,M_inv = preprocessimage(img)\n",
    "    out_img,left_fitx,right_fitx,left_fit,right_fit,ploty,left_lane_inds,right_lane_inds,nonzerox,nonzeroy = lane_find(img_proc)\n",
    "    out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]]   = [255, 0, 0]\n",
    "    out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "    figure.add_subplot(4,2,idx+1)    \n",
    "    plt.imshow(out_img, cmap='gray')\n",
    "    plt.plot(left_fitx, ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def nextframe_lanefind(nxt_img,left_fit,right_fit,Debug=False):\n",
    "    # Assume you now have a new warped binary image from the next frame of video \n",
    "    nonzero  = nxt_img.nonzero()\n",
    "    nonzeroy = np.array(nonzero[0])\n",
    "    nonzerox = np.array(nonzero[1])\n",
    "    margin   = 90\n",
    "    \n",
    "    leftLaneInds  = ((nonzerox > ( left_fit[0]*(nonzeroy**2) +  left_fit[1]*nonzeroy +  left_fit[2] - margin)) & (nonzerox < ( left_fit[0]*(nonzeroy**2) +  left_fit[1]*nonzeroy +  left_fit[2] + margin))) \n",
    "    rightLaneInds = ((nonzerox > (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] - margin)) & (nonzerox < (right_fit[0]*(nonzeroy**2) + right_fit[1]*nonzeroy + right_fit[2] + margin)))  \n",
    "\n",
    "    # Again, extract left and right line pixel positions\n",
    "    leftx  = nonzerox[ leftLaneInds]\n",
    "    lefty  = nonzeroy[ leftLaneInds] \n",
    "    rightx = nonzerox[rightLaneInds]\n",
    "    righty = nonzeroy[rightLaneInds]\n",
    "    \n",
    "    # Fit a new second order polynomial to each lane line\n",
    "    left_fit  = np.polyfit( lefty,  leftx, 2)\n",
    "    right_fit = np.polyfit(righty, rightx, 2)\n",
    "    \n",
    "    # Generate x and y values for plotting\n",
    "    ploty      = np.linspace(0, nxt_img.shape[0]-1, nxt_img.shape[0] )\n",
    "    left_fitx  = left_fit[0]*ploty**2 +  left_fit[1]*ploty +  left_fit[2]\n",
    "    right_fitx = right_fit[0]*ploty**2 + right_fit[1]*ploty + right_fit[2]\n",
    "    \n",
    "    # PLOTTING STUFF #\n",
    "    if(Debug):\n",
    "        # Create an image to draw on and an image to show the selection window\n",
    "        out_img = np.dstack((nxt_img, nxt_img, nxt_img))*255\n",
    "        window_img = np.zeros_like(out_img)\n",
    "\n",
    "        # Color in left and right line pixels\n",
    "        out_img[nonzeroy[left_lane_inds], nonzerox[left_lane_inds]]   = [255, 0, 0]\n",
    "        out_img[nonzeroy[right_lane_inds], nonzerox[right_lane_inds]] = [0, 0, 255]\n",
    "\n",
    "        # Generate a polygon to illustrate the search window area\n",
    "        # And recast the x and y points into usable format for cv2.fillPoly()\n",
    "        left_line_window1  = np.array([np.transpose(np.vstack([left_fitx-margin, ploty]))])\n",
    "        left_line_window2  = np.array([np.flipud(np.transpose(np.vstack([left_fitx+margin, ploty])))])\n",
    "        left_line_pts      = np.hstack((left_line_window1, left_line_window2))\n",
    "        right_line_window1 = np.array([np.transpose(np.vstack([right_fitx-margin, ploty]))])\n",
    "        right_line_window2 = np.array([np.flipud(np.transpose(np.vstack([right_fitx+margin, ploty])))])\n",
    "        right_line_pts     = np.hstack((right_line_window1, right_line_window2))\n",
    "\n",
    "        # Draw the lane onto the warped blank image\n",
    "        cv2.fillPoly(window_img, np.int_([left_line_pts]), (0,255, 0))\n",
    "        cv2.fillPoly(window_img, np.int_([right_line_pts]), (0,255, 0))\n",
    "        result = cv2.addWeighted(out_img, 1, window_img, 0.3, 0)\n",
    "    else:\n",
    "        out_img= []\n",
    "        result = []\n",
    "    \n",
    "    # OUTPUTS #\n",
    "    \n",
    "    yield out_img\n",
    "    yield left_fitx\n",
    "    yield right_fitx\n",
    "    yield left_fit\n",
    "    yield right_fit\n",
    "    yield ploty\n",
    "    yield result\n",
    "\n",
    "figure = plt.figure(1,figsize=(18, 20))\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img      = cv2.imread(fname)\n",
    "    img      = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    img_proc,undist,M_inv = preprocessimage(img)\n",
    "    out_img,left_fitx,right_fitx,left_fit,right_fit,ploty,left_lane_inds,right_lane_inds,nonzerox,nonzeroy  = lane_find(img_proc)\n",
    "    out_img,left_fitx,right_fitx,left_fit,right_fit,ploty,result = nextframe_lanefind(img_proc,left_fit,right_fit,True)\n",
    "    figure.add_subplot(4,2,idx+1)\n",
    "    plt.imshow(result)\n",
    "    plt.plot(left_fitx,  ploty, color='yellow')\n",
    "    plt.plot(right_fitx, ploty, color='yellow')\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# ** Compute Lane Curvature and Error **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def ComputeLaneCurvature(fity, leftx, rightx, ploty):\n",
    "    y_eval = np.max(ploty)\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension\n",
    "    # Fit new polynomials to x,y in world space (meters)\n",
    "    left_fit_cr  = np.polyfit(ploty*ym_per_pix, leftx* xm_per_pix, 2)\n",
    "    right_fit_cr = np.polyfit(ploty*ym_per_pix, rightx*xm_per_pix, 2)\n",
    "    # Calculate the new radii of curvature\n",
    "    left_curverad  = ((1 + (2*left_fit_cr[0] *y_eval*ym_per_pix +  left_fit_cr[1])**2)**1.5) / np.absolute(2* left_fit_cr[0])\n",
    "    right_curverad = ((1 + (2*right_fit_cr[0]*y_eval*ym_per_pix + right_fit_cr[1])**2)**1.5) / np.absolute(2*right_fit_cr[0])\n",
    "    # Now our radius of curvature is in meters\n",
    "    #print(left_curverad, 'm', right_curverad, 'm')\n",
    "    # Example values: 632.1 m    626.2 m\n",
    "    yield left_curverad\n",
    "    yield right_curverad\n",
    "    \n",
    "def ComputeLanePosErr(left, right, width, height):\n",
    "    # Define conversions in x and y from pixels space to meters\n",
    "    ym_per_pix = 30/720  # meters per pixel in y dimension\n",
    "    xm_per_pix = 3.7/700 # meters per pixel in x dimension    \n",
    "    center = (right[0] + left[0]) / 2\n",
    "    err    = center - width/2\n",
    "    posError = err * xm_per_pix\n",
    "    return posError, err"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** PROJECT LANE DETECTED TO IMAGE**\n",
    "Test the projection of the detected lane onto the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def projectlane(warped, M_inv, undist, left_fitx, right_fitx, ploty):\n",
    "                \n",
    "    # Create an image to draw the lines on\n",
    "    warp_zero  = np.zeros_like(undist).astype(np.uint8)\n",
    "\n",
    "    # Recast the x and y points into usable format for cv2.fillPoly()\n",
    "    pts_left  = np.array([np.transpose(np.vstack([left_fitx, ploty]))])\n",
    "    pts_right = np.array([np.flipud(np.transpose(np.vstack([right_fitx, ploty])))])\n",
    "    pts       = np.hstack((pts_left, pts_right))\n",
    "    \n",
    "    # Draw the lane onto the warped blank image\n",
    "    color_warp = cv2.fillPoly(warp_zero, pts.astype(int), (0,255, 0))\n",
    "\n",
    "    # Warp the blank back to original image space using inverse perspective matrix (Minv)\n",
    "    newwarp = cv2.warpPerspective(color_warp, M_inv, (undist.shape[1], undist.shape[0])) \n",
    "    \n",
    "    # Combine the result with the original image\n",
    "    result = cv2.addWeighted(undist, 1, newwarp, 0.3, 0)\n",
    "        \n",
    "    return result\n",
    "\n",
    "figure = plt.figure(1,figsize=(18, 20))\n",
    "for idx, fname in enumerate(testimages):\n",
    "    img            = cv2.imread(fname)\n",
    "    img            = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    img_proc,undist,M_inv = preprocessimage(img)\n",
    "    \n",
    "    out_img,left_fitx,right_fitx,left_fit,right_fit,ploty,left_lane_inds,right_lane_inds,nonzerox,nonzeroy  = lane_find(img_proc)\n",
    "    out_img,left_fitx,right_fitx,left_fit,right_fit,ploty,result = nextframe_lanefind(img_proc,left_fit,right_fit)\n",
    "    result  = projectlane(img_proc, M_inv, undist, left_fitx, right_fitx, ploty)\n",
    "    \n",
    "    figure.add_subplot(4,2,idx+1)   \n",
    "    # Compute Lane Curvature and Position Error\n",
    "    left_curverad,right_curverad = ComputeLaneCurvature(ploty, left_fitx, right_fitx, ploty)\n",
    "    posError, err                = ComputeLanePosErr(left_fitx, right_fitx, width=img.shape[1], height=img.shape[0])\n",
    "    # Draw text on the screen (in unwarped image space).  \n",
    "    # Show position error and left/right curvature values.\n",
    "    font             = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    posErrorString   = \"Pos Error   = %6.2f m\" % (posError)\n",
    "    cv2.putText(result, posErrorString,(50,50), font, 2, (255,255,255),2)\n",
    "    leftLaneCurvStr  = \"Left Curve  = %6.2f m\" % (left_curverad)\n",
    "    rightLaneCurvStr = \"Right Curve = %6.2f m\" % (right_curverad)\n",
    "    cv2.putText(result, leftLaneCurvStr,(50,100), font, 2, (255,255,255),2)\n",
    "    cv2.putText(result, rightLaneCurvStr,(50,150), font, 2, (255,255,255),2)\n",
    "    plt.imshow(result)\n",
    "    plt.xlim(0, 1280)\n",
    "    plt.ylim(720, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** VIDEO PROCESSING PIPELINE **\n",
    "Test video processing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a class to receive the characteristics of each line detection\n",
    "class Line():\n",
    "    def __init__(self):\n",
    "        self.detected       = False                            # was the line detected in the last iteration?\n",
    "        self.left_fit       = None                             #previous frame left lane line fit\n",
    "        self.right_fit      = None                             #previous frame right lane line fit \n",
    "        self.left_fitx      = None                             #previous frame left lane line x fit\n",
    "        self.right_fitx     = None                             #previous frame right lane line x fit\n",
    "        self.savedframecnt  = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Import everything needed to edit/save/watch video clips\n",
    "from moviepy.editor import VideoFileClip\n",
    "from IPython.display import HTML\n",
    "\n",
    "def process_video(frame,GenDebugImgs = False):\n",
    "    \n",
    "    if(GenDebugImgs):\n",
    "        cv2.imwrite(\"frame%i.jpg\" % line.savedframecnt, frame)\n",
    "        line.savedframecnt = line.savedframecnt +1\n",
    "    \n",
    "    # Apply Distortion Correction\n",
    "    undistortedimg = undistort_imgs(frame)\n",
    "    # Apply Binary Thresholding\n",
    "    binary_img     = pipeline_binary_img_test(frame)\n",
    "    # Apply Birds Eye Perspective Transform\n",
    "    Tfm_img,M_inv  = BirdsEyeTransform(binary_img)\n",
    "    masked_img     = mask_bdseye(Tfm_img)\n",
    "    \n",
    "    # Get the lane from the first frame, update the line class \n",
    "    if line.detected == False:\n",
    "        \n",
    "        out_img,left_fitx,right_fitx,left_fit,right_fit,ploty,left_lane_inds,right_lane_inds,nonzerox,nonzeroy = lane_find(masked_img)\n",
    "        line.left_fit   = left_fit\n",
    "        line.right_fit  = right_fit\n",
    "        line.left_fitx  = left_fitx\n",
    "        line.right_fitx = right_fitx\n",
    "        \n",
    "        line.detected = True\n",
    "    # Do a limited search based on the previous lines    \n",
    "    else:\n",
    "        out_img,left_fitx,right_fitx,left_fit,right_fit,ploty,result = nextframe_lanefind(masked_img,line.left_fit,line.right_fit)\n",
    "        \n",
    "        #If the leading coefficient has changed by a factor of 10 then there is a frame where the lane finding is bad\n",
    "        #we should weigh the last frames data more than the current frame\n",
    "        if abs(left_fit[0]) > 10*abs(line.left_fit[0]):\n",
    "            wt_leftprev  = np.zeros_like(line.left_fitx)\n",
    "            wt_leftcur   = np.zeros_like(left_fitx)\n",
    "            wt_rightprev = np.zeros_like(line.right_fitx)\n",
    "            wt_rightcur  = np.zeros_like(right_fitx)\n",
    "            \n",
    "            wt_leftprev  = wt_leftprev  + 0.5\n",
    "            wt_leftcur   = wt_leftcur   + 0.5\n",
    "            wt_rightprev = wt_rightprev + 0.5\n",
    "            wt_rightcur  = wt_rightcur  + 0.5\n",
    "            \n",
    "            left_fitx  = np.hstack(( line.left_fitx, left_fitx))\n",
    "            right_fitx = np.hstack((line.right_fitx,right_fitx))\n",
    "            \n",
    "            wt_left  = np.hstack(( wt_leftprev, wt_leftcur))\n",
    "            wt_right = np.hstack((wt_rightprev,wt_rightcur))\n",
    "            \n",
    "            ploty = np.hstack((ploty,ploty))\n",
    "            \n",
    "            left_fit  = np.polyfit(ploty, left_fitx,2,w=wt_left)\n",
    "            right_fit = np.polyfit(ploty,right_fitx,2,w=wt_right)\n",
    "            \n",
    "            line.left_fit  = (left_fit  + 24* line.left_fit)/25\n",
    "            line.right_fit = (right_fit + 24*line.right_fit)/25\n",
    "            \n",
    "            left_fitx  =  left_fit[0]*(ploty**2) +  left_fit[1]*ploty +  left_fit[2]\n",
    "            right_fitx = right_fit[0]*(ploty**2) + right_fit[1]*ploty + right_fit[2]\n",
    "            \n",
    "        else:\n",
    "            line.left_fit  = ( left_fit + 24* line.left_fit)/25\n",
    "            line.right_fit = (right_fit + 24*line.right_fit)/25\n",
    "            \n",
    "            line.left_fitx = left_fitx\n",
    "            line.right_fitx = right_fitx\n",
    "    \n",
    "    # Project the detected lane     \n",
    "    result  = projectlane(Tfm_img, M_inv, undistortedimg, left_fitx, right_fitx, ploty)\n",
    "    \n",
    "    # Compute Lane Curvature and Position Error\n",
    "    left_curverad,right_curverad = ComputeLaneCurvature(ploty, left_fitx, right_fitx, ploty)\n",
    "    posError, err                = ComputeLanePosErr(left_fitx, right_fitx, width=img.shape[1], height=img.shape[0])\n",
    "    # Draw text on the screen (in unwarped image space).  \n",
    "    # Show position error and left/right curvature values.\n",
    "    font             = cv2.FONT_HERSHEY_SIMPLEX\n",
    "    posErrorString   = \"Pos Error   = %6.2f m\" % (posError)\n",
    "    cv2.putText(result, posErrorString,(50,50), font, 2, (255,255,255),2)\n",
    "    leftLaneCurvStr  = \"Left Curve  = %6.2f m\" % (left_curverad)\n",
    "    rightLaneCurvStr = \"Right Curve = %6.2f m\" % (right_curverad)\n",
    "    cv2.putText(result, leftLaneCurvStr,(50,100), font, 2, (255,255,255),2)\n",
    "    cv2.putText(result, rightLaneCurvStr,(50,150), font, 2, (255,255,255),2)\n",
    "    \n",
    "    return result\n",
    "\n",
    "output = 'output_videos/project_video.mp4'\n",
    "vidclip = VideoFileClip(\"project_video.mp4\")#.subclip(20,25)\n",
    "line = Line()\n",
    "# Process video\n",
    "clip = vidclip.fl_image(process_video)\n",
    "clip.write_videofile(output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
