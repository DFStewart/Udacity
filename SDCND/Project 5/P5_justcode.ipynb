{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# **Project 5: Vehicle Detection and Tracking** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **REFERENCES**\n",
    "https://carnd-forums.udacity.com/questions/38555139/how-to-integrate-heatmap-over-several-frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# **LOAD PACKAGES**\n",
    "Load necessary packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import Packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "import glob\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "%matplotlib inline\n",
    "import matplotlib.image as mpimg\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from skimage.feature import hog\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "import time\n",
    "from random import randint\n",
    "import matplotlib.image as mpimg\n",
    "from scipy.ndimage.measurements import label\n",
    "import pickle\n",
    "from moviepy.editor import VideoFileClip\n",
    "from skimage.feature import hog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **LOAD TEST IMAGES**\n",
    "Load the test images provided by Udacity and GTI training datasets and check to make sure they loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load Test Images\n",
    "imgs_test = glob.glob('test_images/*.jpg')\n",
    "# Load Vehicle Images\n",
    "imgs_gtifar = glob.glob('test_images/vehicles/GTI_Far/*.png')\n",
    "imgs_gtilef = glob.glob('test_images/vehicles/GTI_Left/*.png')\n",
    "imgs_gtirig = glob.glob('test_images/vehicles/GTI_MiddleClose/*.png')\n",
    "imgs_gtimcl = glob.glob('test_images/vehicles/GTI_Right/*.png')\n",
    "imgs_kittie = glob.glob('test_images/vehicles/KITTI_extracted/*.png')\n",
    "imgs_veh    = imgs_gtifar+imgs_gtilef+imgs_gtirig+imgs_gtimcl+imgs_kittie\n",
    "# Load Non Vehicle Images\n",
    "imgs_GTI    = glob.glob('test_images/non-vehicles/GTI/*.png')\n",
    "imgs_ext    = glob.glob('test_images/non-vehicles/Extras/*.png')\n",
    "imgs_nonveh = imgs_GTI+imgs_ext\n",
    "\n",
    "cars    = []\n",
    "notcars = []\n",
    "for image in imgs_veh:\n",
    "    cars.append(image)\n",
    "for image in imgs_nonveh:\n",
    "    notcars.append(image)    \n",
    "    \n",
    "# Test to make sure that the test images are loading properly\n",
    "f1,(ax1,ax2)=plt.subplots(1,2,figsize=(6,6))\n",
    "# Test to make sure that the vehicle images are loading properly\n",
    "ax1.imshow(mpimg.imread(cars[randint(0,200)]))\n",
    "# Test to make sure that the non-vehicle images are loading properly\n",
    "ax2.imshow(mpimg.imread(notcars[randint(0,200)]))\n",
    "\n",
    "# Test to make sure that the test images are loading properly\n",
    "f2,(ax1,ax2)=plt.subplots(1,2,figsize=(6,6))\n",
    "# Test to make sure that the vehicle images are loading properly\n",
    "ax1.imshow(mpimg.imread(cars[randint(0,200)]))\n",
    "# Test to make sure that the non-vehicle images are loading properly\n",
    "ax2.imshow(mpimg.imread(notcars[randint(0,200)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** DATA ANALYSIS **\n",
    "Look at the distribution of data. Make sure it is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print('Total Vehicle Images:',len(cars))\n",
    "print('Veh Images Size:',np.shape(cars))\n",
    "print('Total Non-Vehicle Images:',len(notcars))\n",
    "print('Non Veh Images Size:',np.shape(notcars))\n",
    "print('Total Test Images:',len(imgs_test))\n",
    "print('Test Images Size:',np.shape(imgs_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** Color Histogram Transform Analysis **\n",
    "Compute the color histogram and analyze across images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img_veh = cv2.imread(cars[randint(0,2000)])\n",
    "test_img_veh = cv2.cvtColor(test_img_veh, cv2.COLOR_BGR2YCrCb)\n",
    "# Compute the histogram of the RGB channels separately\n",
    "yhist = np.histogram(test_img_veh[:,:,0], bins=32, range=(0,256))\n",
    "crhist = np.histogram(test_img_veh[:,:,1], bins=32, range=(0,256))\n",
    "cbhist = np.histogram(test_img_veh[:,:,2], bins=32, range=(0,256))\n",
    "# Generating bin centers\n",
    "bin_edges   = yhist[1]\n",
    "bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "# Concatenate the histograms into a single feature vector\n",
    "hist_features = np.concatenate((yhist[0], crhist[0], cbhist[0]))\n",
    "\n",
    "# Plot a figure with all three bar charts\n",
    "if ghist is not None:\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    plt.subplot(141)\n",
    "    plt.imshow(test_img_veh)\n",
    "    plt.subplot(142)\n",
    "    plt.bar(bin_centers, rhist[0], width = 4)\n",
    "    plt.xlim(0, 256)\n",
    "    plt.title('Y Histogram',fontsize=20)\n",
    "    plt.subplot(143)\n",
    "    plt.bar(bin_centers, ghist[0], width = 4)\n",
    "    plt.xlim(0, 256)\n",
    "    plt.title('Cr Histogram',fontsize=20)\n",
    "    plt.subplot(144)\n",
    "    plt.bar(bin_centers, bhist[0], width = 4)\n",
    "    plt.xlim(0, 256)\n",
    "    plt.title('Cb Histogram',fontsize=20)\n",
    "    fig.tight_layout()\n",
    "else:\n",
    "    print('Your function is returning None for at least one variable...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** COLOR SPACES ANALYSIS **\n",
    "Look at transformations in different color spaces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot3d(ax, pixels, colors_rgb,\n",
    "        axis_labels=list(\"RGB\"), axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    #fig = plt.figure(figsize=(8, 8))\n",
    "    #ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "\n",
    "# Read a random car image\n",
    "test_img_veh = cv2.imread(cars[randint(0,2000)])\n",
    "test_img_veh = cv2.cvtColor(test_img_veh, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "# Select a small fraction of pixels to plot by subsampling it\n",
    "scale = max(test_img_veh.shape[0], test_img_veh.shape[1], 64) / 64  # at most 64 rows and columns\n",
    "img_small = cv2.resize(test_img_veh, (np.int(test_img_veh.shape[1] / scale), np.int(test_img_veh.shape[0] / scale)), interpolation=cv2.INTER_NEAREST)\n",
    "\n",
    "# Convert subsampled image to desired color space(s)\n",
    "img_small_RGB   = cv2.cvtColor(img_small, cv2.COLOR_BGR2RGB)  # OpenCV uses BGR, matplotlib likes RGB\n",
    "img_small_HSV   = cv2.cvtColor(img_small, cv2.COLOR_BGR2HSV)\n",
    "img_small_HLS   = cv2.cvtColor(img_small, cv2.COLOR_BGR2HLS)\n",
    "img_small_LUV   = cv2.cvtColor(img_small, cv2.COLOR_BGR2LUV)\n",
    "img_small_YUV   = cv2.cvtColor(img_small, cv2.COLOR_BGR2YUV)\n",
    "img_small_YCrCb = cv2.cvtColor(img_small, cv2.COLOR_BGR2YCrCb)\n",
    "img_small_rgb   = img_small_RGB / 255.  # scaled to [0, 1], only for plotting\n",
    "\n",
    "# Plotting Result\n",
    "f   = plt.figure(figsize=(20,10))\n",
    "ax1 = f.add_subplot(1, 3, 1)\n",
    "ax1.imshow(test_img_veh)\n",
    "ax2 = f.add_subplot(1, 3, 2,projection='3d')\n",
    "plot3d(ax2,img_small_RGB, img_small_rgb, axis_labels=list(\"RGB\"))\n",
    "ax2.set_xlabel('R', fontsize=16, labelpad=16)\n",
    "ax2.set_ylabel('G', fontsize=16, labelpad=16)\n",
    "ax2.set_zlabel('B', fontsize=16, labelpad=16)\n",
    "ax3 = f.add_subplot(1, 3, 3,projection='3d')\n",
    "plot3d(ax3,img_small_HSV, img_small_rgb, axis_labels=list(\"HSV\"))\n",
    "ax3.set_xlabel('H', fontsize=16, labelpad=16)\n",
    "ax3.set_ylabel('S', fontsize=16, labelpad=16)\n",
    "ax3.set_zlabel('V', fontsize=16, labelpad=16)\n",
    "\n",
    "f   = plt.figure(figsize=(20,10))\n",
    "ax1 = f.add_subplot(1, 3, 1,projection='3d')\n",
    "plot3d(ax1,img_small_HLS, img_small_rgb, axis_labels=list(\"HLS\"))\n",
    "ax1.set_xlabel('H', fontsize=16, labelpad=16)\n",
    "ax1.set_ylabel('L', fontsize=16, labelpad=16)\n",
    "ax1.set_zlabel('S', fontsize=16, labelpad=16)\n",
    "ax2 = f.add_subplot(1, 3, 2,projection='3d')\n",
    "plot3d(ax2,img_small_LUV, img_small_rgb, axis_labels=list(\"LUV\"))\n",
    "ax2.set_xlabel('L', fontsize=16, labelpad=16)\n",
    "ax2.set_ylabel('U', fontsize=16, labelpad=16)\n",
    "ax2.set_zlabel('V', fontsize=16, labelpad=16)\n",
    "ax3 = f.add_subplot(1, 3, 3,projection='3d')\n",
    "plot3d(ax3,img_small_YCrCb, img_small_rgb, axis_labels=list(\"YCrCb\"))\n",
    "ax3.set_xlabel('Y', fontsize=16, labelpad=16)\n",
    "ax3.set_ylabel('Cr', fontsize=16, labelpad=16)\n",
    "ax3.set_zlabel('Cb', fontsize=16, labelpad=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** SPATIAL COLOR BINNING **\n",
    "Test spatial binning of color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Read in an image\n",
    "# You can also read cutout2, 3, 4 etc. to see other examples\n",
    "test_img_veh = cv2.imread(cars[randint(0,2000)])\n",
    "test_img_veh = cv2.cvtColor(test_img_veh, cv2.COLOR_BGR2RGB)\n",
    "# Define a function to compute color histogram features  \n",
    "# Pass the color_space flag as 3-letter all caps string\n",
    "# like 'HSV' or 'LUV' etc.\n",
    "# KEEP IN MIND IF YOU DECIDE TO USE THIS FUNCTION LATER\n",
    "# IN YOUR PROJECT THAT IF YOU READ THE IMAGE WITH \n",
    "# cv2.imread() INSTEAD YOU START WITH BGR COLOR!\n",
    "def test_bin_spatial(img, color_space='RGB', size=(32, 32)):\n",
    "    # Convert image to new color space (if specified)\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)             \n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(feature_image, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "    \n",
    "feature_vec_hsv   = test_bin_spatial(test_img_veh, color_space='HSV', size=(32, 32))\n",
    "feature_vec_luv   = test_bin_spatial(test_img_veh, color_space='LUV', size=(32, 32))\n",
    "feature_vec_hls   = test_bin_spatial(test_img_veh, color_space='HLS', size=(32, 32))\n",
    "feature_vec_yuv   = test_bin_spatial(test_img_veh, color_space='YUV', size=(32, 32))\n",
    "feature_vec_ycrcb = test_bin_spatial(test_img_veh, color_space='YCrCb', size=(32, 32))\n",
    "\n",
    "# Plot features\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.subplot(161)\n",
    "plt.imshow(test_img_veh)\n",
    "plt.title('Hi Res Original Image')\n",
    "plt.subplot(162)\n",
    "plt.plot(feature_vec_hsv)\n",
    "plt.title('HSV')\n",
    "plt.subplot(163)\n",
    "plt.plot(feature_vec_luv)\n",
    "plt.title('LUV')\n",
    "plt.subplot(164)\n",
    "plt.plot(feature_vec_hls)\n",
    "plt.title('HLS')\n",
    "plt.subplot(165)\n",
    "plt.plot(feature_vec_yuv)\n",
    "plt.title('YUV')\n",
    "plt.subplot(166)\n",
    "plt.plot(feature_vec_ycrcb)\n",
    "plt.title('YCrCb')\n",
    "\n",
    "size = (8, 8)\n",
    "small_img = cv2.resize(test_img_veh, size)\n",
    "\n",
    "feature_vec_hsv   = test_bin_spatial(small_img, color_space='HSV',   size=size)\n",
    "feature_vec_luv   = test_bin_spatial(small_img, color_space='LUV',   size=size)\n",
    "feature_vec_hls   = test_bin_spatial(small_img, color_space='HLS',   size=size)\n",
    "feature_vec_yuv   = test_bin_spatial(small_img, color_space='YUV',   size=size)\n",
    "feature_vec_ycrcb = test_bin_spatial(small_img, color_space='YCrCb', size=size)\n",
    "\n",
    "# Plot features\n",
    "fig = plt.figure(figsize=(20,5))\n",
    "plt.subplot(161)\n",
    "plt.imshow(small_img)\n",
    "plt.title('Lo Res Original Image')\n",
    "plt.subplot(162)\n",
    "plt.plot(feature_vec_hsv)\n",
    "plt.title('HSV')\n",
    "plt.subplot(163)\n",
    "plt.plot(feature_vec_luv)\n",
    "plt.title('LUV')\n",
    "plt.subplot(164)\n",
    "plt.plot(feature_vec_hls)\n",
    "plt.title('HLS')\n",
    "plt.subplot(165)\n",
    "plt.plot(feature_vec_yuv)\n",
    "plt.title('YUV')\n",
    "plt.subplot(166)\n",
    "plt.plot(feature_vec_ycrcb)\n",
    "plt.title('YCrCb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** GRADIENT THRESHOLDING TESTING **\n",
    "Test gradient thresholding, absolute sobel, magnitude sobel.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_sobel_absx(img,sobel_kernel,threshx_min=20,threshx_max=80):\n",
    "    # SOBEL: Directional X \n",
    "    img_dx     = cv2.Sobel(img,cv2.CV_64F, 1, 0)\n",
    "    img_absx   = np.absolute(img_dx)\n",
    "    img_sobelx = np.uint8(255*img_absx/np.max(img_absx))\n",
    "    sobel_dirx = np.zeros_like(img_sobelx)\n",
    "    sobel_dirx[(img_sobelx >= threshx_min) & (img_sobelx <= threshx_max)] = 1\n",
    "    return sobel_dirx\n",
    "def test_sobel_absy(img,sobel_kernel,threshy_min=80,threshy_max=225):\n",
    "    # SOBEL: Directional Y \n",
    "    img_dy     = cv2.Sobel(img,cv2.CV_64F, 0, 1)\n",
    "    img_absy   = np.absolute(img_dy)\n",
    "    img_sobely = np.uint8(255*img_absy/np.max(img_absy))\n",
    "    sobel_diry = np.zeros_like(img_sobely)\n",
    "    sobel_diry[(img_sobely >= threshy_min) & (img_sobely <= threshy_max)] = 1\n",
    "    return sobel_diry\n",
    "def test_sobel_mag(img,sobel_kernel,threshmag_min =  20,threshmag_max = 120):  \n",
    "    # SOBEL: Magnitude\n",
    "    sobelmx = cv2.Sobel(img,cv2.CV_64F, 1, 0)\n",
    "    sobelmy = cv2.Sobel(img,cv2.CV_64F, 0, 1)\n",
    "    mag_sobel    = np.sqrt(sobelmx**2 + sobelmx**2)\n",
    "    scaled_sobel = np.uint8(mag_sobel*255/np.max(mag_sobel))\n",
    "    sobel_mag    = np.zeros_like(scaled_sobel)\n",
    "    sobel_mag[(scaled_sobel>=threshmag_min) & (scaled_sobel<=threshmag_max) ]=1\n",
    "    return sobel_mag\n",
    "def test_sobel_dir(img,sobel_kernel,threshd_min= 0.5,threshd_max= 1.2):\n",
    "    # SOBEL: Calculate gradient direction\n",
    "    sobeldx    = cv2.Sobel(img,cv2.CV_64F,1,0, ksize=sobel_kernel)\n",
    "    sobeldy    = cv2.Sobel(img,cv2.CV_64F,0,1, ksize=sobel_kernel)\n",
    "    abs_sobelx = np.absolute(sobeldx)\n",
    "    abs_sobely = np.absolute(sobeldy)\n",
    "    dir_grad   = np.arctan2(abs_sobely, abs_sobelx)\n",
    "    sobel_dir    = np.zeros_like(dir_grad)\n",
    "    sobel_dir[(dir_grad>=threshd_min) & (dir_grad<=threshd_max)] = 1\n",
    "    return sobel_dir\n",
    "def test_combined_color(img):\n",
    "    r = img[:,:,0]\n",
    "    g = img[:,:,1]\n",
    "    b = img[:,:,2]\n",
    "    color_binary = np.zeros_like(b)\n",
    "    yellow = [[215, 255], [140, 255], [  0, 160]]\n",
    "    white  = [[225, 255], [225, 255], [225, 255]]\n",
    "    color_binary[((( r > 215) & (r <  255)) &(( g > 140) & (g <  255)) &(( b >   0) & (b <  160)))\n",
    "                 |(((r > 225) & (r <  255)) &(( g > 225) & (g <  255)) &(( b > 225) & (b <  255)))] = 1\n",
    "    return color_binary\n",
    "    \n",
    "test_img_veh = cv2.imread(cars[randint(0,2000)])\n",
    "img       = cv2.cvtColor(test_img_veh, cv2.COLOR_BGR2RGB)\n",
    "img_hls   = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "img_gs    = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "hls       = img_hls\n",
    "gs        = img_gs\n",
    "rgb       = img\n",
    "h_channel = hls[:,:,0]\n",
    "l_channel = hls[:,:,1]\n",
    "s_channel = hls[:,:,2]\n",
    "    \n",
    "color_binary = test_combined_color(rgb);\n",
    "    \n",
    "#sobel_chan = gs\n",
    "sobel_chan = s_channel\n",
    "    \n",
    "bin_out_absx = test_sobel_absx(sobel_chan,9,50,255)\n",
    "bin_out_absy = test_sobel_absy(sobel_chan,9,50,255)\n",
    "bin_out_mag  = test_sobel_mag(sobel_chan, 9,50,255)\n",
    "bin_out_dir  = test_sobel_dir(sobel_chan, 9,0,255)\n",
    "    \n",
    "# Visualize Thresholded Images\n",
    "plt.figure(0)\n",
    "f, (ax1, ax2, ax3, ax4) = plt.subplots(1, 4, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Original', fontsize=30)\n",
    "ax2.imshow(bin_out_absx, cmap='gray')\n",
    "ax2.set_title('Sobel ABSx', fontsize=30)\n",
    "ax3.imshow(bin_out_absy, cmap='gray')\n",
    "ax3.set_title('Sobel ABSy', fontsize=30)\n",
    "ax4.imshow(bin_out_dir, cmap='gray')\n",
    "ax4.set_title('Sobel Mag', fontsize=30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** HOG FEATURES TESTING **\n",
    "Here I test HOG features and parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to return HOG features and visualization\n",
    "def test_hog_features(img, orient, pix_per_cell, cell_per_block, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                                  visualise=True, feature_vector=False)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Generate a random index to look at a car image\n",
    "test_img_veh = cv2.imread(cars[randint(0,2000)])\n",
    "img          = cv2.cvtColor(test_img_veh, cv2.COLOR_BGR2RGB)\n",
    "img_ycrcb    = cv2.cvtColor(test_img_veh, cv2.COLOR_RGB2YCrCb)\n",
    "\n",
    "# Define HOG parameters\n",
    "orient         = 9  #\n",
    "pix_per_cell   = 16 # format (pix_per_cell,pix_per_cell)\n",
    "cell_per_block = 4  # format (cell_per_block,cell_per_block)\n",
    "\n",
    "# Call our function with vis=True to see an image output\n",
    "features, hog_image = test_hog_features(img_ycrcb[:,:,1], orient, \n",
    "                        pix_per_cell, cell_per_block, \n",
    "                        vis=True, feature_vec=False)\n",
    "\n",
    "# Plot the examples\n",
    "fig = plt.figure()\n",
    "f, (ax1, ax2) = plt.subplots(1, 2, figsize=(20,10))\n",
    "ax1.imshow(img)\n",
    "ax1.set_title('Example Car Image')\n",
    "ax2.imshow(hog_image, cmap='hot')\n",
    "ax2.set_title('HOG Visualization')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** TEST FEATURE EXTRACTION **\n",
    "Test different combinations of feature extraction methods, test feature normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to compute binned color features  \n",
    "def bin_spatial(img, color_space='RGB', size=(32, 32)):\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)   \n",
    "    # Use cv2.resize().ravel() to create the feature vector\n",
    "    features = cv2.resize(img, size).ravel() \n",
    "    # Return the feature vector\n",
    "    return features\n",
    "\n",
    "def plot3d(pixels, colors_rgb,\n",
    "        axis_labels=list(\"RGB\"), axis_limits=[(0, 255), (0, 255), (0, 255)]):\n",
    "    \"\"\"Plot pixels in 3D.\"\"\"\n",
    "\n",
    "    # Create figure and 3D axes\n",
    "    fig = plt.figure(figsize=(8, 8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    # Set axis limits\n",
    "    ax.set_xlim(*axis_limits[0])\n",
    "    ax.set_ylim(*axis_limits[1])\n",
    "    ax.set_zlim(*axis_limits[2])\n",
    "\n",
    "    # Set axis labels and sizes\n",
    "    ax.tick_params(axis='both', which='major', labelsize=14, pad=8)\n",
    "    ax.set_xlabel(axis_labels[0], fontsize=16, labelpad=16)\n",
    "    ax.set_ylabel(axis_labels[1], fontsize=16, labelpad=16)\n",
    "    ax.set_zlabel(axis_labels[2], fontsize=16, labelpad=16)\n",
    "\n",
    "    # Plot pixel values with colors given in colors_rgb\n",
    "    ax.scatter(\n",
    "        pixels[:, :, 0].ravel(),\n",
    "        pixels[:, :, 1].ravel(),\n",
    "        pixels[:, :, 2].ravel(),\n",
    "        c=colors_rgb.reshape((-1, 3)), edgecolors='none')\n",
    "\n",
    "    return ax  # return Axes3D object for further manipulation\n",
    "\n",
    "# Define a function to compute color histogram features  \n",
    "def color_hist(img, nbins=32, bins_range=(0, 256)):\n",
    "    # Compute the histogram of the RGB channels separately\n",
    "    rhist = np.histogram(img[:,:,0], bins=nbins, range=bins_range)\n",
    "    ghist = np.histogram(img[:,:,1], bins=nbins, range=bins_range)\n",
    "    bhist = np.histogram(img[:,:,2], bins=nbins, range=bins_range)\n",
    "    # Generating bin centers\n",
    "    bin_edges = rhist[1]\n",
    "    bin_centers = (bin_edges[1:]  + bin_edges[0:len(bin_edges)-1])/2\n",
    "    # Concatenate the histograms into a single feature vector\n",
    "    hist_features = np.concatenate((rhist[0], ghist[0], bhist[0]))\n",
    "    # Return the individual histograms, bin_centers and feature vector\n",
    "    return hist_features\n",
    "\n",
    "def sobel_mag(img_rgb,sobel_kernel,threshmag_min =  20,threshmag_max = 120):  \n",
    "    # SOBEL: Magnitude\n",
    "    gray    = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelmx = cv2.Sobel(gray,cv2.CV_64F, 1, 0)\n",
    "    sobelmy = cv2.Sobel(gray,cv2.CV_64F, 0, 1)\n",
    "    mag_sobel    = np.sqrt(sobelmx**2 + sobelmx**2)\n",
    "    scaled_sobel = np.uint8(mag_sobel*255/np.max(mag_sobel))\n",
    "    sobel_mag    = np.zeros_like(scaled_sobel)\n",
    "    sobel_mag[(scaled_sobel>=threshmag_min) & (scaled_sobel<=threshmag_max) ]=1\n",
    "    return sobel_mag\n",
    "\n",
    "# HOG Features\n",
    "def hog_features(img, orient=9, pix_per_cell=8, cell_per_block=2, vis=False, feature_vec=True):\n",
    "    if vis == True:\n",
    "        features, hog_image = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                                  cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                                  visualise=True, feature_vector=False)\n",
    "        return features, hog_image\n",
    "    else:      \n",
    "        features = hog(img, orientations=orient, pixels_per_cell=(pix_per_cell, pix_per_cell),\n",
    "                       cells_per_block=(cell_per_block, cell_per_block), transform_sqrt=False, \n",
    "                       visualise=False, feature_vector=feature_vec)\n",
    "        return features\n",
    "\n",
    "# Define a function to extract features from a list of images\n",
    "# Have this function call bin_spatial() and color_hist()\n",
    "def extract_features(imgs, cspace='RGB', spatial_size=(32, 32),\n",
    "                     hist_bins=32, hist_range=(0, 256),\n",
    "                     hog_orient=9, hog_pixpcell=8, hog_cellpblock=2,hog_ch='ALL',\n",
    "                     add_spatial = False, add_hist = False, add_HOG = False):\n",
    "    # Create a list to append feature vectors to\n",
    "    features = []\n",
    "    # Iterate through the list of images\n",
    "    for file in imgs:\n",
    "        features_file = []\n",
    "        # Read in each one by one\n",
    "        image = mpimg.imread(file)\n",
    "        #image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        # apply color conversion if other than 'RGB'\n",
    "        if cspace != 'RGB':\n",
    "            if cspace == 'HSV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "            elif cspace == 'LUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2LUV)\n",
    "            elif cspace == 'HLS':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2HLS)\n",
    "            elif cspace == 'YUV':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)\n",
    "            elif cspace == 'YCrCb':\n",
    "                feature_image = cv2.cvtColor(image, cv2.COLOR_RGB2YCrCb)    \n",
    "        else: \n",
    "            feature_image = np.copy(image)      \n",
    "        if(add_spatial):\n",
    "            spatial_features = []\n",
    "            # Apply bin_spatial() to get spatial color features\n",
    "            spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "            features_file.append(spatial_features)\n",
    "        if(add_hist):\n",
    "            hist_features = []\n",
    "            # Apply color_hist() also with a color space option now\n",
    "            hist_features = color_hist(feature_image, nbins=hist_bins, bins_range=hist_range)\n",
    "            features_file.append(hist_features)\n",
    "        if(add_HOG):\n",
    "            if hog_ch == 'ALL':\n",
    "                hog_feat = []\n",
    "                for channel in range(feature_image.shape[2]):\n",
    "                    hog_feat.extend(hog_features(feature_image[:,:,channel], \n",
    "                                        orient, pix_per_cell, cell_per_block, \n",
    "                                        vis=False, feature_vec=True))      \n",
    "            else:\n",
    "                hog_feat = hog_features(feature_image[:,:,hog_ch], orient, \n",
    "                            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            features_file.append(hog_feat)\n",
    "        features.append(np.concatenate(features_file))\n",
    "    # Return list of feature vectors\n",
    "    return features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** FEATURE EXTRACTION METHODS TESTING **\n",
    "Now that the feature extraction pipeline is setup, test different combinations of feature extraction methods, i.e. color hist, spatial binning and HOG features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPATIAL BINNING + COLOR HISTOGRAM\n",
    "(No HOG Features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Generate a random index to look at a car image\n",
    "test_img_veh = cv2.imread(cars[randint(0,2000)])\n",
    "#test_img_veh = cv2.cvtColor(test_img_veh, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "test_img_nonveh = cv2.imread(notcars[randint(0,2000)])\n",
    "#test_img_nonveh = cv2.cvtColor(test_img_nonveh, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "car_features    = extract_features(cars,    cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256),\n",
    "                        hog_orient=9, hog_pixpcell=8, hog_cellpblock=2,hog_ch=2,\n",
    "                        add_spatial = True, add_hist = True, add_HOG = False)\n",
    "\n",
    "notcar_features = extract_features(notcars, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256),\n",
    "                        hog_orient=9, hog_pixpcell=8, hog_cellpblock=2,hog_ch=2,\n",
    "                        add_spatial = True, add_hist = True, add_HOG = False)\n",
    "\n",
    "if len(car_features) > 0:\n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    car_ind = np.random.randint(0, len(imgs_veh))\n",
    "    # Plot an example of raw and scaled features\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(mpimg.imread(cars[car_ind]))\n",
    "    plt.title('Original Image')\n",
    "    plt.subplot(132)\n",
    "    plt.plot(X[car_ind])\n",
    "    plt.title('Raw Features')\n",
    "    plt.subplot(133)\n",
    "    plt.plot(scaled_X[car_ind])\n",
    "    plt.title('Normalized Features')\n",
    "    fig.tight_layout()\n",
    "else: \n",
    "    print('Your function only returns empty feature vectors...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SPATIAL BINNING + COLOR HISTOGRAM + HOG FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "car_features_hog = extract_features(cars, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256),\n",
    "                        hog_orient=9, hog_pixpcell=8, hog_cellpblock=2,hog_ch='ALL',\n",
    "                        add_spatial = True, add_hist = True, add_HOG = True)\n",
    "\n",
    "notcar_features_hog = extract_features(notcars, cspace='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, hist_range=(0, 256),\n",
    "                        hog_orient=9, hog_pixpcell=8, hog_cellpblock=2,hog_ch='ALL',\n",
    "                        add_spatial = True, add_hist = True, add_HOG = True)\n",
    "\n",
    "if len(car_features_hog) > 0:\n",
    "    # Create an array stack of feature vectors\n",
    "    X_hog = np.vstack((car_features_hog, notcar_features_hog)).astype(np.float64)                        \n",
    "    # Fit a per-column scaler\n",
    "    X_hog_scaler = StandardScaler().fit(X_hog)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X_hog = X_hog_scaler.transform(X_hog)\n",
    "    car_ind = np.random.randint(0, len(imgs_veh))\n",
    "    # Plot an example of raw and scaled features\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    plt.subplot(131)\n",
    "    plt.imshow(mpimg.imread(cars[car_ind]))\n",
    "    plt.title('Original Image')\n",
    "    plt.subplot(132)\n",
    "    plt.plot(X_hog[car_ind])\n",
    "    plt.title('Raw Features')\n",
    "    plt.subplot(133)\n",
    "    plt.plot(scaled_X_hog[car_ind])\n",
    "    plt.title('Normalized Features')\n",
    "    fig.tight_layout()\n",
    "else: \n",
    "    print('Your function only returns empty feature vectors...')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** TRAIN A CLASSIFIER **\n",
    "Train a linear SVC on the features previously extracted above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def prep_data_training(car_features,notcar_features):\n",
    "    # Create an array stack of feature vectors\n",
    "    X = np.vstack((car_features, notcar_features)).astype(np.float64)\n",
    "    # Fit a per-column scaler\n",
    "    X_scaler = StandardScaler().fit(X)\n",
    "    # Apply the scaler to X\n",
    "    scaled_X = X_scaler.transform(X)\n",
    "    # Define a labels vector based on features lists\n",
    "    y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "    print ('scaled_X.shape:',scaled_X.shape)\n",
    "    print ('y.shape:       ',y.shape)\n",
    "    \n",
    "    return scaled_X,y\n",
    "    \n",
    "def split_data(scaled_X,y,test_size=0.2):\n",
    "    rand_state = np.random.randint(0, 10)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(scaled_X, y,test_size=test_size,random_state=rand_state)\n",
    "    print ('X_train shape:',X_train.shape)\n",
    "    print ('X_test  shape:',X_test.shape)\n",
    "    print ('y_train shape:',y_train.shape)\n",
    "    print ('y_test  shape:',y_test.shape)\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "def Train_LinearSVC(X_train,y_train,X_test,y_test):\n",
    "    svc = LinearSVC()\n",
    "    t=time.time()\n",
    "    svc.fit(X_train, y_train)\n",
    "    t2 = time.time()\n",
    "    print('It took ',round(t2-t, 2), 'seconds to train')\n",
    "    print('Test Accuracy: {0:0.4f}%'.format(svc.score(X_test, y_test)*100))\n",
    "    print('  Predictions:', svc.predict(X_test[0:10]))\n",
    "    print('       Labels:', y_test[0:10])\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_X,y = prep_data_training(car_features,notcar_features)\n",
    "X_train, X_test, y_train, y_test = split_data(scaled_X,y)\n",
    "Train_LinearSVC(X_train,y_train,X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "scaled_X_hog,y_hog = prep_data_training(car_features_hog,notcar_features_hog)\n",
    "Xhog_train, Xhog_test, yhog_train, yhog_test = split_data(scaled_X_hog,y_hog)\n",
    "Train_LinearSVC(Xhog_train,yhog_train,Xhog_test,yhog_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** SLIDING WINDOWS **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def draw_boxes(img, bboxes, color=(0, 0, 255), thick=6):\n",
    "    # Make a copy of the image\n",
    "    imcopy = np.copy(img)\n",
    "    # Iterate through the bounding boxes\n",
    "    for bbox in bboxes:\n",
    "        # Draw a rectangle given bbox coordinates\n",
    "        cv2.rectangle(imcopy, bbox[0], bbox[1], color, thick)\n",
    "    # Return the image copy with boxes drawn\n",
    "    return imcopy\n",
    "    \n",
    "# Define a function that takes an image,\n",
    "# start and stop positions in both x and y, \n",
    "# window size (x and y dimensions),  \n",
    "# and overlap fraction (for both x and y)\n",
    "def slide_window(img, x_start_stop=[None, None], y_start_stop=[None, None], \n",
    "                    xy_window=(64, 64), xy_overlap=(0.5, 0.5)):\n",
    "    # If x and/or y start/stop positions not defined, set to image size\n",
    "    if x_start_stop[0] == None:\n",
    "        x_start_stop[0] = 0\n",
    "    if x_start_stop[1] == None:\n",
    "        x_start_stop[1] = img.shape[1]\n",
    "    if y_start_stop[0] == None:\n",
    "        y_start_stop[0] = 0\n",
    "    if y_start_stop[1] == None:\n",
    "        y_start_stop[1] = img.shape[0]\n",
    "    # Compute the span of the region to be searched    \n",
    "    xspan = x_start_stop[1] - x_start_stop[0]\n",
    "    yspan = y_start_stop[1] - y_start_stop[0]\n",
    "    # Compute the number of pixels per step in x/y\n",
    "    nx_pix_per_step = np.int(xy_window[0]*(1 - xy_overlap[0]))\n",
    "    ny_pix_per_step = np.int(xy_window[1]*(1 - xy_overlap[1]))\n",
    "    # Compute the number of windows in x/y\n",
    "    nx_buffer = np.int(xy_window[0]*(xy_overlap[0]))\n",
    "    ny_buffer = np.int(xy_window[1]*(xy_overlap[1]))\n",
    "    nx_windows = np.int((xspan-nx_buffer)/nx_pix_per_step) \n",
    "    ny_windows = np.int((yspan-ny_buffer)/ny_pix_per_step) \n",
    "    # Initialize a list to append window positions to\n",
    "    window_list = []\n",
    "    # Loop through finding x and y window positions\n",
    "    # Note: you could vectorize this step, but in practice\n",
    "    # you'll be considering windows one by one with your\n",
    "    # classifier, so looping makes sense\n",
    "    for ys in range(ny_windows):\n",
    "        for xs in range(nx_windows):\n",
    "            # Calculate window position\n",
    "            startx = xs*nx_pix_per_step + x_start_stop[0]\n",
    "            endx = startx + xy_window[0]\n",
    "            starty = ys*ny_pix_per_step + y_start_stop[0]\n",
    "            endy = starty + xy_window[1]\n",
    "            # Append window position to list\n",
    "            window_list.append(((startx, starty), (endx, endy)))\n",
    "    # Return the list of windows\n",
    "    return window_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test_img = mpimg.imread(imgs_test[2])\n",
    "windows  = slide_window(test_img, x_start_stop=[700, 1260], y_start_stop=[360, 648], \n",
    "                        xy_window=(128, 128), xy_overlap=(0.85, 0.85))\n",
    "                       \n",
    "window_img = draw_boxes(test_img, windows, color=(0, 0, 255), thick=6)                    \n",
    "plt.imshow(window_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** SEARCH AND CLASSIFY**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define a function to extract features from a single image window\n",
    "# This function is very similar to extract_features()\n",
    "# just for a single image rather than list of images\n",
    "def single_img_features(img, color_space='RGB', spatial_size=(32, 32),\n",
    "                        hist_bins=32, orient=9, \n",
    "                        pix_per_cell=8, cell_per_block=2, hog_channel=0,\n",
    "                        spatial_feat=True, hist_feat=True, hog_feat=True):    \n",
    "    #1) Define an empty list to receive features\n",
    "    img_features = []\n",
    "    #2) Apply color conversion if other than 'RGB'\n",
    "    if color_space != 'RGB':\n",
    "        if color_space == 'HSV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n",
    "        elif color_space == 'LUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2LUV)\n",
    "        elif color_space == 'HLS':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "        elif color_space == 'YUV':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YUV)\n",
    "        elif color_space == 'YCrCb':\n",
    "            feature_image = cv2.cvtColor(img, cv2.COLOR_RGB2YCrCb)\n",
    "    else: feature_image = np.copy(img)      \n",
    "    #3) Compute spatial features if flag is set\n",
    "    if spatial_feat == True:\n",
    "        spatial_features = bin_spatial(feature_image, size=spatial_size)\n",
    "        #4) Append features to list\n",
    "        img_features.append(spatial_features)\n",
    "    #5) Compute histogram features if flag is set\n",
    "    if hist_feat == True:\n",
    "        hist_features = color_hist(feature_image, nbins=hist_bins)\n",
    "        #6) Append features to list\n",
    "        img_features.append(hist_features)\n",
    "    #7) Compute HOG features if flag is set\n",
    "    if hog_feat == True:\n",
    "        if hog_channel == 'ALL':\n",
    "            hog_feat = []\n",
    "            for channel in range(feature_image.shape[2]):\n",
    "                #hog_feat.extend(hog_features(feature_image[:,:,channel], \n",
    "                #                    orient, pix_per_cell, cell_per_block, \n",
    "                #                    vis=False, feature_vec=True))    \n",
    "                feature_array = hog(feature_image[:,:,channel], \n",
    "                                    orientations=orient, \n",
    "                                    pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                                    cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                    visualise=False, \n",
    "                                    feature_vector=True)\n",
    "                hog_feat.extend(feature_array)\n",
    "        else:\n",
    "            #hog_feat = hog_features(feature_image[:,:,hog_channel], orient, \n",
    "            #            pix_per_cell, cell_per_block, vis=False, feature_vec=True)\n",
    "            feature_array = hog(feature_image[:,:,channel], \n",
    "                                    orientations=orient, \n",
    "                                    pixels_per_cell=(pix_per_cell, pix_per_cell), \n",
    "                                    cells_per_block=(cell_per_block, cell_per_block), \n",
    "                                    visualise=False, \n",
    "                                    feature_vector=True)\n",
    "            hog_feat = feature_array\n",
    "        #8) Append features to list\n",
    "        img_features.append(hog_feat)\n",
    "\n",
    "    #9) Return concatenated array of features\n",
    "    return np.concatenate(img_features)\n",
    "\n",
    "# Define a function you will pass an image \n",
    "# and the list of windows to be searched (output of slide_windows())\n",
    "def search_windows(img, windows, clf, scaler, color_space='RGB', \n",
    "                    spatial_size=(32, 32), hist_bins=32, \n",
    "                    hist_range=(0, 256), orient=9, \n",
    "                    pix_per_cell=8, cell_per_block=2, \n",
    "                    hog_channel=0, spatial_feat=True, \n",
    "                    hist_feat=True, hog_feat=True):\n",
    "\n",
    "    #1) Create an empty list to receive positive detection windows\n",
    "    on_windows = []\n",
    "    #2) Iterate over all windows in the list\n",
    "    for window in windows:\n",
    "        #3) Extract the test window from original image\n",
    "        test_img = cv2.resize(img[window[0][1]:window[1][1], window[0][0]:window[1][0]], (64, 64))      \n",
    "        #4) Extract features for that window using single_img_features()\n",
    "        features = single_img_features(test_img, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)\n",
    "        #5) Scale extracted features to be fed to classifier\n",
    "        test_features = scaler.transform(np.array(features).reshape(1, -1))\n",
    "        #6) Predict using your classifier\n",
    "        prediction = clf.predict(test_features)\n",
    "        #7) If positive (prediction == 1) then save the window\n",
    "        if prediction == 1:\n",
    "            on_windows.append(window)\n",
    "    #8) Return windows for positive detections\n",
    "    return on_windows\n",
    "\n",
    "## Parameters for tweaking\n",
    "color_space    = 'YCrCb'    # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "orient         = 9          # HOG orientations\n",
    "pix_per_cell   = 16         # HOG pixels per cell\n",
    "cell_per_block = 4          # HOG cells per block\n",
    "hog_channel    = \"ALL\"      # Can be 0, 1, 2, or \"ALL\"\n",
    "spatial_size   = (16, 16)   # Spatial binning dimensions\n",
    "hist_bins      = 16         # Number of histogram bins\n",
    "spatial_feat   = True       # Spatial features on or off\n",
    "hist_feat      = True       # Histogram features on or off\n",
    "hog_feat       = True       # HOG features on or off\n",
    "y_start_stop   = [400, 640] # Min and max in y to search in slide_window()\n",
    "\n",
    "car_features = extract_features(cars, cspace=color_space, spatial_size=spatial_size,\n",
    "                     hist_bins=hist_bins, hist_range=(0, 256),\n",
    "                     hog_orient=orient, hog_pixpcell=pix_per_cell, hog_cellpblock=cell_per_block,hog_ch=hog_channel,\n",
    "                     add_spatial = spatial_feat, add_hist = hist_feat, add_HOG = hog_feat)\n",
    "    \n",
    "notcar_features = extract_features(notcars, cspace=color_space, spatial_size=spatial_size,\n",
    "                     hist_bins=hist_bins, hist_range=(0, 256),\n",
    "                     hog_orient=orient, hog_pixpcell=pix_per_cell, hog_cellpblock=cell_per_block,hog_ch=hog_channel,\n",
    "                     add_spatial = spatial_feat, add_hist = hist_feat, add_HOG = hog_feat)\n",
    "\n",
    "X = np.vstack((car_features, notcar_features)).astype(np.float64)                        \n",
    "# Fit a per-column scaler\n",
    "X_scaler = StandardScaler().fit(X)\n",
    "# Apply the scaler to X\n",
    "scaled_X = X_scaler.transform(X)\n",
    "\n",
    "# Define the labels vector\n",
    "y = np.hstack((np.ones(len(car_features)), np.zeros(len(notcar_features))))\n",
    "\n",
    "# Split up data into randomized training and test sets\n",
    "rand_state = np.random.randint(0, 100)\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    scaled_X, y, test_size=0.25, random_state=rand_state)\n",
    "\n",
    "print('Using:',orient,'orientations',pix_per_cell,\n",
    "    'pixels per cell and', cell_per_block,'cells per block')\n",
    "print('Feature vector length:', len(X_train[0]))\n",
    "# Use a linear SVC \n",
    "svc = LinearSVC(C=0.01)\n",
    "# Check the training time for the SVC\n",
    "t=time.time()\n",
    "svc.fit(X_train, y_train)\n",
    "t2 = time.time()\n",
    "print(round(t2-t, 2), 'Seconds to train SVC...')\n",
    "# Check the score of the SVC\n",
    "print('Test Accuracy of SVC = ', round(svc.score(X_test, y_test), 4))\n",
    "# Check the prediction time for a single sample\n",
    "t=time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save Classifier to Pickle File\n",
    "classifier_pickle = {}\n",
    "classifier_pickle[\"svc\"] = svc\n",
    "classifier_pickle[\"X_scaler\"] = X_scaler\n",
    "classifier_pickle[\"scaled_X\"] = scaled_X\n",
    "pickle.dump(classifier_pickle, open(\"output_images/Classifier.p\", \"wb\"));\n",
    "print('Saved pickle file with Classifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_single_image(image):\n",
    "    draw_image = np.copy(image)\n",
    "    # Uncomment the following line if you extracted training\n",
    "    # data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "    # image you are searching is a .jpg (scaled 0 to 255)\n",
    "    image = image.astype(np.float32)/255\n",
    "    windows         = []\n",
    "    xy_window_sizes = [64,96,128]\n",
    "    y_start_stop    = [[360, 550],[360, 576],[360, 648]]\n",
    "    #y_start_stop    = [[400, 640],[400, 640],[400, 640]]\n",
    "    for idx in range(len(xy_window_sizes)):\n",
    "        windows += slide_window(image, x_start_stop=[700, 1260], y_start_stop=y_start_stop[idx], \n",
    "                            xy_window=xy_window_sizes, xy_overlap=(0.85, 0.85))\n",
    "\n",
    "    hot_windows = search_windows(image, windows, svc, X_scaler, color_space=color_space, \n",
    "                            spatial_size=spatial_size, hist_bins=hist_bins, \n",
    "                            orient=orient, pix_per_cell=pix_per_cell, \n",
    "                            cell_per_block=cell_per_block, \n",
    "                            hog_channel=hog_channel, spatial_feat=spatial_feat, \n",
    "                            hist_feat=hist_feat, hog_feat=hog_feat)                       \n",
    "\n",
    "    window_img = draw_boxes(draw_image, hot_windows, color=(0, 0, 255), thick=6)                    \n",
    "    return window_img, hot_windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for idx, fname in enumerate(imgs_test):\n",
    "    image = mpimg.imread(imgs_test[idx])\n",
    "    window_img, hot_windows = test_single_image(image)\n",
    "    #\n",
    "    bbox_pickle = {}\n",
    "    all_bboxes = hot_windows\n",
    "    bbox_pickle[\"bboxes\"] = all_bboxes\n",
    "    pickle_str = 'output_images/bbox_pickle_' + str(idx) + \".p\"\n",
    "    pickle.dump(bbox_pickle, open(pickle_str, \"wb\"));\n",
    "    print('Saved pickle file with bboxes')\n",
    "    #\n",
    "    plt.figure(idx) \n",
    "    # Visualize Output\n",
    "    fig = plt.figure(figsize=(12,4))\n",
    "    plt.imshow(window_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def add_heat(heatmap, bbox_list):\n",
    "    # Iterate through list of bboxes\n",
    "    for box in bbox_list:\n",
    "        # Add += 1 for all pixels inside each bbox\n",
    "        # Assuming each \"box\" takes the form ((x1, y1), (x2, y2))\n",
    "        heatmap[box[0][1]:box[1][1], box[0][0]:box[1][0]] += 1\n",
    "        #heatmap = np.clip(heatmap, 0, 255)\n",
    "    # Return updated heatmap\n",
    "    return heatmap# Iterate through list of bboxes\n",
    "    \n",
    "def apply_threshold(heatmap, threshold):\n",
    "    # Zero out pixels below the threshold\n",
    "    heatmap[heatmap <= threshold] = 0\n",
    "    # Return thresholded map\n",
    "    return heatmap\n",
    "\n",
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "def test_heatmap(idx):\n",
    "    # Read in a pickle file with bboxes saved\n",
    "    # Each item in the \"all_bboxes\" list will contain a \n",
    "    # list of boxes for one of the images shown above\n",
    "    pickle_str = 'output_images/bbox_pickle_' + str(idx) + \".p\"\n",
    "    box_list = pickle.load( open(pickle_str, \"rb\" ))\n",
    "\n",
    "    # Read in image similar to one shown above \n",
    "    image   = cv2.imread(imgs_test[idx])\n",
    "    image   = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    #image   = image.astype(np.float32)/255\n",
    "    heat    = np.zeros_like(image[:,:,0]).astype(np.float)\n",
    "\n",
    "    # Add heat to each box in box list\n",
    "    heat = add_heat(heat,box_list['bboxes'])\n",
    "\n",
    "    # Apply threshold to help remove false positives\n",
    "    heat = apply_threshold(heat,5)\n",
    "\n",
    "    # Visualize the heatmap when displaying    \n",
    "    heatmap = np.clip(heat, 0, 255)\n",
    "\n",
    "    # Find final boxes from heatmap using label function\n",
    "    labels   = label(heatmap)\n",
    "    draw_img = draw_labeled_bboxes(np.copy(image), labels)\n",
    "    return heatmap,draw_img,labels\n",
    "\n",
    "for idx, fname in enumerate(imgs_test):\n",
    "    fig = plt.figure(figsize=(20,20))\n",
    "    heatmap,draw_img,labels = test_heatmap(idx)\n",
    "    plt.subplot(121)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Car Positions')\n",
    "    plt.subplot(122)\n",
    "    plt.imshow(heatmap, cmap='hot')\n",
    "    plt.title('Heat Map')\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def draw_labeled_bboxes(img, labels):\n",
    "    # Iterate through all detected cars\n",
    "    for car_number in range(1, labels[1]+1):\n",
    "        # Find pixels with each car_number label value\n",
    "        nonzero = (labels[0] == car_number).nonzero()\n",
    "        # Identify x and y values of those pixels\n",
    "        nonzeroy = np.array(nonzero[0])\n",
    "        nonzerox = np.array(nonzero[1])\n",
    "        # Define a bounding box based on min/max x and y\n",
    "        bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "        # Draw the box on the image\n",
    "        cv2.rectangle(img, bbox[0], bbox[1], (0,0,255), 6)\n",
    "    # Return the image\n",
    "    return img\n",
    "\n",
    "for idx, fname in enumerate(imgs_test):\n",
    "    fig = plt.figure(figsize=(10,20))\n",
    "    heatmap,draw_img,labels = test_heatmap(idx)\n",
    "    draw_img = draw_labeled_bboxes(draw_img, labels)\n",
    "    plt.imshow(draw_img)\n",
    "    plt.title('Vehicle Bounding Boxes:\\n', fontsize=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** VIDEO PIPELINE **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frame_count = 1\n",
    "class VehDetClass:\n",
    "    def __init__(self):\n",
    "        self.bboxes         = []\n",
    "        self.avg_box        = []\n",
    "        self.color_space    = 'YCrCb'    # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "        self.orient         = 9          # HOG orientations\n",
    "        self.pix_per_cell   = 16         # HOG pixels per cell\n",
    "        self.cell_per_block = 4          # HOG cells per block\n",
    "        self.hog_channel    = \"ALL\"      # Can be 0, 1, 2, or \"ALL\"\n",
    "        self.spatial_size   = (16, 16)   # Spatial binning dimensions\n",
    "        self.hist_bins      = 16         # Number of histogram bins\n",
    "        self.hist_range     = (0,255)    # Histogram range\n",
    "        self.spatial_feat   = True       # Spatial features on or off\n",
    "        self.hist_feat      = True       # Histogram features on or off\n",
    "        self.hog_feat       = True       # HOG features on or off\n",
    "        self.y_start_stop   = (380, 650) # Min and max in y to search in sl0000000000ide_window()\n",
    "        self.x_start_stop   = (700,1240) # Min and max in x to search in slide_window() #1180\n",
    "        classifier_pickle   = pickle.load(open(\"output_images/Classifier.p\", \"rb\" ))\n",
    "        self.svc            = classifier_pickle['svc']\n",
    "        self.X_scaler       = classifier_pickle['X_scaler']\n",
    "        self.xy_window      = (64, 64)\n",
    "        self.xy_overlap     = (0.85, 0.85)\n",
    "        self.frame_count    = 10    # Number of frames to average boxes over\n",
    "        self.heatmap_thresh = 10\n",
    "        \n",
    "        #color_space    = 'YCrCb'      # Can be RGB, HSV, LUV, HLS, YUV, YCrCb\n",
    "        #orient         = 9          # HOG orientations\n",
    "        #pix_per_cell   = 16         # HOG pixels per cell\n",
    "        #cell_per_block = 2          # HOG cells per block\n",
    "        #hog_channel    = \"ALL\"      # Can be 0, 1, 2, or \"ALL\"\n",
    "        #spatial_size   = (16, 16)   # Spatial binning dimensions\n",
    "        #hist_bins      = 16         # Number of histogram bins\n",
    "        #spatial_feat   = True       # Spatial features on or off\n",
    "        #hist_feat      = True       # Histogram features on or off\n",
    "        #hog_feat       = True       # HOG features on or off\n",
    "        #y_start_stop   = [360, 650] # Min and max in y to search in slide_window()\n",
    "    \n",
    "    # Add the last frame_count\n",
    "    def append_boxes(self, bboxes):\n",
    "        self.bboxes.append(bboxes)\n",
    "        self.bboxes = self.bboxes[-frame_count:]\n",
    "        #print(np.size(self.bboxes))\n",
    "        \n",
    "    # Take all of the boxes, average them and produce heatmap\n",
    "    def add_heatmap(self,img):\n",
    "        heatmap  = np.zeros_like(img[:,:,0]).astype(np.float)\n",
    "        for bboxes in self.bboxes:\n",
    "            add_heat(heatmap, bboxes)    \n",
    "        heatmap = apply_threshold(heatmap,self.heatmap_thresh)\n",
    "        labels  = label(heatmap)\n",
    "        return labels\n",
    "    \n",
    "    #Compute the centroid of the boxes\n",
    "    def find_centroids(self,bboxes):\n",
    "        centroids = []\n",
    "        #box[0][0] x1\n",
    "        #box[1][0] x2\n",
    "        #box[0][1] y1\n",
    "        #box[1][1] y2\n",
    "        for box in bboxes:\n",
    "                center_x = int((box[0][0]+box[1][0])/2)\n",
    "                center_y = int((box[0][1]+box[1][1])/2)\n",
    "                centroids.append((center_x,center_y))\n",
    "        return centroids\n",
    "    \n",
    "     #Compute the size of the boxes\n",
    "    def find_size(self,bboxes):\n",
    "        sizes = []\n",
    "        #box[0][0] x1\n",
    "        #box[1][0] x2\n",
    "        #box[0][1] y1\n",
    "        #box[1][1] y2\n",
    "        for box in bboxes:\n",
    "                width  = int((box[1][0]-box[0][0])/2)\n",
    "                height = int((box[1][1]-box[0][1])/2)\n",
    "                sizes.append((width,height))\n",
    "        return sizes\n",
    "    \n",
    "    #Compute the distance between 2 centroids\n",
    "    def dist_btwn_centroids(self,center1,center2):\n",
    "        dist = np.sqrt((center2[0]-center1[0])**2+(center2[1]-center1[1])**2)\n",
    "        return dist\n",
    "    \n",
    "    def compute_bboxes(self,img, labels):\n",
    "        # Iterate through all detected cars\n",
    "        draw_img = np.copy(img)\n",
    "        bboxes = []\n",
    "        numdetcars = 0\n",
    "        for car_number in range(1, labels[1]+1):\n",
    "            # Find pixels with each car_number label value\n",
    "            nonzero = (labels[0] == car_number).nonzero()\n",
    "            # Identify x and y values of those pixels\n",
    "            nonzeroy = np.array(nonzero[0])\n",
    "            nonzerox = np.array(nonzero[1])\n",
    "            # Define a bounding box based on min/max x and y\n",
    "            bbox = ((np.min(nonzerox), np.min(nonzeroy)), (np.max(nonzerox), np.max(nonzeroy)))\n",
    "            bboxes.append(bbox)\n",
    "            numdetcars = numdetcars+1\n",
    "        return bboxes,numdetcars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def video_pipeline3(img,vehdet=None):\n",
    "    Debug = False\n",
    "    if vehdet is None:\n",
    "        vehdet = VehDetClass()\n",
    "    draw_image = np.copy(img)\n",
    "    # Uncomment the following line if you extracted training\n",
    "    # data from .png images (scaled 0 to 1 by mpimg) and the\n",
    "    # image you are searching is a .jpg (scaled 0 to 255)\n",
    "    img = img.astype(np.float32)/255\n",
    "\n",
    "    xy_window_sizes = [64,96,128]\n",
    "    y_start_stop    = [[360, 504],[360, 576],[360, 648]]\n",
    "    windows = []\n",
    "    for idx in range(len(xy_window_sizes)):\n",
    "        temp_windows = slide_window(img, \n",
    "                               x_start_stop = vehdet.x_start_stop, \n",
    "                               y_start_stop = y_start_stop[idx], \n",
    "                               xy_window    = (xy_window_sizes[idx],xy_window_sizes[idx]), \n",
    "                               xy_overlap   = vehdet.xy_overlap)\n",
    "        windows = windows+temp_windows\n",
    "\n",
    "    hot_windows = search_windows(img, \n",
    "                                 windows, \n",
    "                                 clf           = vehdet.svc, \n",
    "                                 scaler        = vehdet.X_scaler, \n",
    "                                 color_space   = vehdet.color_space, \n",
    "                                 spatial_size  = vehdet.spatial_size, \n",
    "                                 hist_bins     = vehdet.hist_bins, \n",
    "                                 hist_range    = vehdet.hist_range, \n",
    "                                 orient        = vehdet.orient, \n",
    "                                 pix_per_cell  = vehdet.pix_per_cell, \n",
    "                                 cell_per_block= vehdet.cell_per_block, \n",
    "                                 hog_channel   = vehdet.hog_channel, \n",
    "                                 spatial_feat  = vehdet.spatial_feat, \n",
    "                                 hist_feat     = vehdet.hist_feat, \n",
    "                                 hog_feat      = vehdet.hog_feat)     \n",
    "\n",
    "    # Get the boxes from the last 10 frames of video stick them in vehdet.bboxes\n",
    "    vehdet.append_boxes(hot_windows)\n",
    "    heatmap = vehdet.add_heatmap(draw_image)\n",
    "    out_img = draw_labeled_bboxes(draw_image, heatmap) \n",
    "    return out_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "video_output = 'output_project_video.mp4'\n",
    "clip = VideoFileClip('project_video.mp4')#.subclip(19,20)\n",
    "\n",
    "output_clip = clip.fl_image(video_pipeline3) #color images only\n",
    "%time output_clip.write_videofile(video_output, audio=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
